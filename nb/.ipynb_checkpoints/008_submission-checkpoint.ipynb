{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- 以下のノートブックを参考にして、lightGBMモデルを作成する\n",
    "> https://www.kaggle.com/martxelo/fe-and-ensemble-mlp-and-lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '008'\n",
    "isSmallSet = False\n",
    "LENGTH = 7000\n",
    "\n",
    "PATH_TRAIN = './../data/input/train_clean.csv'\n",
    "PATH_TEST = './../data/input/test_clean.csv'\n",
    "PATH_SMPLE_SUB = './../data/input/sample_submission.csv'\n",
    "DIR_OUTPUT = './../data/output/'\n",
    "cp = ['#f8b195', '#f67280', '#c06c84', '#6c5b7b', '#355c7d']\n",
    "sr = 10*10**3  # 10 kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fastprogress import progress_bar\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from dtreeviz.trees import dtreeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(true, pred):\n",
    "    return f1_score(true, pred, average='macro')\n",
    "\n",
    "def get_df_batch(df, batch):\n",
    "    idxs = df['batch'] == batch\n",
    "    assert any(idxs), 'そのようなbatchはありません'\n",
    "    return df[idxs]\n",
    "    \n",
    "def get_signal_mv_mean(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).mean().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "def get_signal_mv_std(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).std().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "def get_signal_mv_min(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).min().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "def get_signal_mv_max(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).max().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, X_valid, y_valid):\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        if self.metric == 'auc':\n",
    "            y_valid_score = self.model.predict_proba(X_valid)[:, 1]\n",
    "            fpr, tpr, thresholds = roc_curve(y_valid, y_valid_score)\n",
    "            self.base_score = auc(fpr, tpr)\n",
    "        else:\n",
    "            pred = np.round(self.model.predict(X_valid)).astype('int8')\n",
    "            self.base_score = self.metric(y_valid, pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(X_valid.columns):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            y_valid_pred = self.model.predict(df_perm)\n",
    "            if self.metric == 'auc':\n",
    "                y_valid_score = self.model.predict_proba(df_perm)[:, 1]\n",
    "                fpr, tpr, thresholds = roc_curve(y_valid, y_valid_score)\n",
    "                score = auc(fpr, tpr)\n",
    "            else:\n",
    "                score = self.metric(y_valid, np.round(y_valid_pred).astype('int8'))\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "#         plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(X, y, X_te, lgbm_params, random_state=5, n_fold=5, verbose=50, early_stopping_rounds=100, show_fig=True):\n",
    "    # using features\n",
    "    print(f'features({len(X.columns)}): \\n{X.columns}') if not verbose==0 else None\n",
    "\n",
    "#     folds = KFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "\n",
    "    scores = []\n",
    "    oof = np.zeros(len(X))\n",
    "    oof_round = np.zeros(len(X))\n",
    "    test_pred = np.zeros(len(X_te))\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for fold_n, (train_idx, valid_idx) in enumerate(folds.split(X, y=y)):\n",
    "        if  verbose==0:\n",
    "            pass\n",
    "        else:\n",
    "            print('\\n------------------')\n",
    "            print(f'- Fold {fold_n + 1}/{N_FOLD} started at {time.ctime()}')\n",
    "\n",
    "        # prepare dataset\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        # train\n",
    "        model = LGBMRegressor(**lgbm_params, n_estimators=N_ESTIMATORS)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=verbose,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        # pred\n",
    "        y_valid_pred = model.predict(X_valid, model.best_iteration_)\n",
    "        y_valid_pred_round = np.round(y_valid_pred).astype('int8')\n",
    "        _test_pred = model.predict(X_te, model.best_iteration_)\n",
    "\n",
    "        # permutation importance\n",
    "        pi = permutation_importance(model, f1_macro) # model と metric を渡す\n",
    "        pi.compute(X_valid, y_valid)\n",
    "        pi_result = pi.df_result\n",
    "\n",
    "        # result\n",
    "        oof[valid_idx] = y_valid_pred\n",
    "        oof_round[valid_idx] = y_valid_pred_round\n",
    "        score = f1_score(y_valid, y_valid_pred_round, average='macro')\n",
    "        scores.append(score)\n",
    "        test_pred += _test_pred\n",
    "        df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "        if verbose==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'---> f1-score(macro) valid: {f1_score(y_valid, y_valid_pred_round, average=\"macro\"):.4f}')\n",
    "            print('')\n",
    "\n",
    "\n",
    "    print('====== finish ======')\n",
    "    print('score list:', scores)\n",
    "    print('CV mean score(f1_macro): {0:.4f}, std: {1:.4f}'.format(np.mean(scores), np.std(scores)))\n",
    "    print(f'oof score(f1_macro): {f1_score(y, oof_round, average=\"macro\"):.4f}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    if show_fig==False:\n",
    "        pass\n",
    "    else:\n",
    "        # visualization\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot([0, 10], [0, 10], color='gray')\n",
    "        plt.scatter(y, oof, alpha=0.05, color=cp[1])\n",
    "        plt.xlabel('true')\n",
    "        plt.ylabel('pred')\n",
    "        plt.show()\n",
    "        \n",
    "        # permutation importance\n",
    "        plt.figure(figsize=(15, int(0.25*len(X.columns))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=False)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "\n",
    "    # submission\n",
    "    test_pred = test_pred/N_FOLD\n",
    "    test_pred_round = np.round(test_pred).astype('int8')\n",
    "      \n",
    "    return test_pred_round, test_pred, oof_round, oof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "ref: https://www.kaggle.com/martxelo/fe-and-ensemble-mlp-and-lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradients(s, n_grads=4):\n",
    "    '''\n",
    "    Calculate gradients for a pandas series. Returns the same number of samples\n",
    "    '''\n",
    "    grads = pd.DataFrame()\n",
    "    \n",
    "    g = s.values\n",
    "    for i in range(n_grads):\n",
    "        g = np.gradient(g)\n",
    "        grads['grad_' + str(i+1)] = g\n",
    "        \n",
    "    return grads\n",
    "\n",
    "def calc_low_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies low pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.3, n_filts)\n",
    "    \n",
    "    low_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='low')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return low_pass\n",
    "\n",
    "def calc_high_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies high pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.1, n_filts)\n",
    "    \n",
    "    high_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='high')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return high_pass\n",
    "\n",
    "def calc_roll_stats(s, windows=[10, 50, 100, 500, 1000]):\n",
    "    '''\n",
    "    Calculates rolling stats like mean, std, min, max...\n",
    "    '''\n",
    "    roll_stats = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        roll_stats['roll_mean_' + str(w)] = s.rolling(window=w, min_periods=1).mean()\n",
    "        roll_stats['roll_std_' + str(w)] = s.rolling(window=w, min_periods=1).std()\n",
    "        roll_stats['roll_min_' + str(w)] = s.rolling(window=w, min_periods=1).min()\n",
    "        roll_stats['roll_max_' + str(w)] = s.rolling(window=w, min_periods=1).max()\n",
    "        roll_stats['roll_range_' + str(w)] = roll_stats['roll_max_' + str(w)] - roll_stats['roll_min_' + str(w)]\n",
    "        roll_stats['roll_q10_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.10)\n",
    "        roll_stats['roll_q25_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.25)\n",
    "        roll_stats['roll_q50_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.50)\n",
    "        roll_stats['roll_q75_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.75)\n",
    "        roll_stats['roll_q90_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.90)\n",
    "    \n",
    "    # add zeros when na values (std)\n",
    "    roll_stats = roll_stats.fillna(value=0)\n",
    "             \n",
    "    return roll_stats\n",
    "\n",
    "def calc_ewm(s, windows=[10, 50, 100, 500, 1000]):\n",
    "    '''\n",
    "    Calculates exponential weighted functions\n",
    "    '''\n",
    "    ewm = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n",
    "        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n",
    "        \n",
    "    # add zeros when na values (std)\n",
    "    ewm = ewm.fillna(value=0)\n",
    "        \n",
    "    return ewm\n",
    "\n",
    "def add_features(s):\n",
    "    '''\n",
    "    All calculations together\n",
    "    '''\n",
    "    \n",
    "    gradients = calc_gradients(s)\n",
    "    low_pass = calc_low_pass(s)\n",
    "    high_pass = calc_high_pass(s)\n",
    "#     roll_stats = calc_roll_stats(s)\n",
    "#     ewm = calc_ewm(s)\n",
    "    \n",
    "#     return pd.concat([s, gradients, low_pass, high_pass, roll_stats, ewm], axis=1)\n",
    "    return pd.concat([s, gradients, low_pass, high_pass], axis=1)\n",
    "\n",
    "\n",
    "def divide_and_add_features(s, signal_size=500000):\n",
    "    '''\n",
    "    Divide the signal in bags of \"signal_size\".\n",
    "    Normalize the data dividing it by 15.0\n",
    "    '''\n",
    "    # normalize\n",
    "    s = s/15.0\n",
    "    \n",
    "    ls = []\n",
    "    for i in progress_bar(range(int(s.shape[0]/signal_size))):\n",
    "        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n",
    "        sig_featured = add_features(sig)\n",
    "        ls.append(sig_featured)\n",
    "    \n",
    "    return pd.concat(ls, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(PATH_TRAIN)\n",
    "df_te = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "処理のしやすさのために、バッチ番号を振る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = []\n",
    "for n in range(10):\n",
    "    batchs = np.ones(500000)*n\n",
    "    batch_list.append(batchs.astype(int))\n",
    "batch_list = np.hstack(batch_list)\n",
    "df_tr['batch'] = batch_list\n",
    "\n",
    "batch_list = []\n",
    "for n in range(4):\n",
    "    batchs = np.ones(500000)*n\n",
    "    batch_list.append(batchs.astype(int))\n",
    "batch_list = np.hstack(batch_list)\n",
    "df_te['batch'] = batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "smallset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isSmallSet:\n",
    "    print('small set mode')\n",
    "    # train\n",
    "    batchs = df_tr['batch'].values\n",
    "    dfs = []\n",
    "    for i_bt, bt in enumerate(df_tr['batch'].unique()):\n",
    "        idxs = batchs == bt\n",
    "        _df = df_tr[idxs][:LENGTH].copy()\n",
    "        dfs.append(_df)\n",
    "    df_tr = pd.concat(dfs).reset_index(drop=True)\n",
    "    \n",
    "    # test\n",
    "    batchs = df_te['batch'].values\n",
    "    dfs = []\n",
    "    for i_bt, bt in enumerate(df_te['batch'].unique()):\n",
    "        idxs = batchs == bt\n",
    "        _df = df_te[idxs][:LENGTH].copy()\n",
    "        dfs.append(_df)\n",
    "    df_te = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10/10 00:04<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4/4 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### apply every feature to data\n",
    "X = divide_and_add_features(df_tr['signal'])\n",
    "X_te = divide_and_add_features(df_te['signal'])\n",
    "y = df_tr['open_channels'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "N_ESTIMATORS = 200          # 最大学習回数\n",
    "# N_ESTIMATORS = 20          # 最大学習回数\n",
    "VERBOSE = 50               # 300回ごとに評価する\n",
    "EARLY_STOPPING_ROUNDS = 30  # 200回の学習でよくならなければ、学習をとめる\n",
    "N_JOBS = multiprocessing.cpu_count() - 2\n",
    "N_FOLD = 4\n",
    "KFOLD_SEED = 0\n",
    "\n",
    "# lgbm_params\n",
    "# lgbm_params = {'objective': 'huber',\n",
    "lgbm_params = {'objective': 'regression',\n",
    "              \"metric\": 'rmse',\n",
    "#               'reg_alpha': 0.1,\n",
    "#               'reg_lambda': 0.1,\n",
    "              \"boosting_type\": \"gbdt\",\n",
    "              'learning_rate': 0.1,\n",
    "              'n_jobs': N_JOBS,\n",
    "# #               \"subsample_freq\": 1,\n",
    "# #               \"subsample\": 1,\n",
    "#               \"bagging_seed\": 2,\n",
    "# #               \"verbosity\": -1,\n",
    "#     'num_leaves': 51, 'max_depth': 158, 'min_chiled_samples': 15, 'min_chiled_weight': 1, 'learning_rate': 0.07, 'colsample_bytree': 0.8\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features(45): \n",
      "Index(['signal', 'grad_1', 'grad_2', 'grad_3', 'grad_4', 'lowpass_lf_0.0100',\n",
      "       'lowpass_ff_0.0100', 'lowpass_lf_0.0154', 'lowpass_ff_0.0154',\n",
      "       'lowpass_lf_0.0239', 'lowpass_ff_0.0239', 'lowpass_lf_0.0369',\n",
      "       'lowpass_ff_0.0369', 'lowpass_lf_0.0570', 'lowpass_ff_0.0570',\n",
      "       'lowpass_lf_0.0880', 'lowpass_ff_0.0880', 'lowpass_lf_0.1359',\n",
      "       'lowpass_ff_0.1359', 'lowpass_lf_0.2100', 'lowpass_ff_0.2100',\n",
      "       'lowpass_lf_0.3244', 'lowpass_ff_0.3244', 'lowpass_lf_0.5012',\n",
      "       'lowpass_ff_0.5012', 'highpass_lf_0.0100', 'highpass_ff_0.0100',\n",
      "       'highpass_lf_0.0163', 'highpass_ff_0.0163', 'highpass_lf_0.0264',\n",
      "       'highpass_ff_0.0264', 'highpass_lf_0.0430', 'highpass_ff_0.0430',\n",
      "       'highpass_lf_0.0699', 'highpass_ff_0.0699', 'highpass_lf_0.1136',\n",
      "       'highpass_ff_0.1136', 'highpass_lf_0.1848', 'highpass_ff_0.1848',\n",
      "       'highpass_lf_0.3005', 'highpass_ff_0.3005', 'highpass_lf_0.4885',\n",
      "       'highpass_ff_0.4885', 'highpass_lf_0.7943', 'highpass_ff_0.7943'],\n",
      "      dtype='object')\n",
      "\n",
      "------------------\n",
      "- Fold 1/4 started at Sun Apr 26 11:30:54 2020\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's rmse: 0.368197\tvalid_1's rmse: 0.369297\n",
      "[100]\ttraining's rmse: 0.352045\tvalid_1's rmse: 0.353861\n",
      "[150]\ttraining's rmse: 0.342793\tvalid_1's rmse: 0.345355\n",
      "[200]\ttraining's rmse: 0.336817\tvalid_1's rmse: 0.339883\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's rmse: 0.336817\tvalid_1's rmse: 0.339883\n",
      "---> f1-score(macro) valid: 0.8510\n",
      "\n",
      "\n",
      "------------------\n",
      "- Fold 2/4 started at Sun Apr 26 11:35:51 2020\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's rmse: 0.368287\tvalid_1's rmse: 0.368833\n",
      "[100]\ttraining's rmse: 0.351421\tvalid_1's rmse: 0.352399\n",
      "[150]\ttraining's rmse: 0.342696\tvalid_1's rmse: 0.3441\n",
      "[200]\ttraining's rmse: 0.336894\tvalid_1's rmse: 0.338807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's rmse: 0.336894\tvalid_1's rmse: 0.338807\n",
      "---> f1-score(macro) valid: 0.8525\n",
      "\n",
      "\n",
      "------------------\n",
      "- Fold 3/4 started at Sun Apr 26 11:40:50 2020\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's rmse: 0.368695\tvalid_1's rmse: 0.368426\n",
      "[100]\ttraining's rmse: 0.351953\tvalid_1's rmse: 0.352342\n",
      "[150]\ttraining's rmse: 0.342896\tvalid_1's rmse: 0.343741\n",
      "[200]\ttraining's rmse: 0.337473\tvalid_1's rmse: 0.338809\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's rmse: 0.337473\tvalid_1's rmse: 0.338809\n",
      "---> f1-score(macro) valid: 0.8515\n",
      "\n",
      "\n",
      "------------------\n",
      "- Fold 4/4 started at Sun Apr 26 11:45:46 2020\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's rmse: 0.36829\tvalid_1's rmse: 0.3704\n",
      "[100]\ttraining's rmse: 0.351864\tvalid_1's rmse: 0.354451\n",
      "[150]\ttraining's rmse: 0.343556\tvalid_1's rmse: 0.346654\n",
      "[200]\ttraining's rmse: 0.337072\tvalid_1's rmse: 0.34071\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's rmse: 0.337072\tvalid_1's rmse: 0.34071\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-0e18726cb6c9>\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(X, y, X_te, lgbm_params, random_state, n_fold, verbose, early_stopping_rounds, show_fig)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0my_valid_pred_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# permutation importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    664\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 665\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2414\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# change non-float data to float data, need to copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred_round, test_pred, oof_round, oof = train_lgbm(X, y, X_te, lgbm_params,\n",
    "                                                        n_fold=N_FOLD, \n",
    "                                                        verbose=VERBOSE, \n",
    "                                                        random_state=KFOLD_SEED, \n",
    "                                                        early_stopping_rounds=EARLY_STOPPING_ROUNDS, \n",
    "                                                        show_fig=True\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_path = f'{DIR_OUTPUT}submission_nb{NB}_cv_{f1_macro(y, oof_round):.4f}.csv'\n",
    "sub = pd.read_csv(PATH_SMPLE_SUB)\n",
    "sub['open_channels'] = test_pred_round\n",
    "print(f'save path: {save_path}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sub.to_csv(save_path, index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
