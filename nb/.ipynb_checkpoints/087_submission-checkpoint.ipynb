{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- nb067ベース(cv:0.94102, sub:0.945)\n",
    "- wavenet(not_roll)\n",
    "- nb067(lgbm_clf(deep))のproba使う\n",
    "- ROLL_FEATS = True\n",
    "- MOD_BATCH7 = False\n",
    "- n_fold: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '087'\n",
    "isSmallSet = False\n",
    "if isSmallSet:\n",
    "    LENGTH = 7000\n",
    "else:\n",
    "    LENGTH = 500_000\n",
    "\n",
    "ROLL_FEATS = True\n",
    "MOD_BATCH7 = False\n",
    "PATH_PROBAS = './../data/output_ignore/probas_nb067_cv_0.9410.npz'\n",
    "\n",
    "PATH_TRAIN = './../data/input/train_clean.csv'\n",
    "PATH_TEST = './../data/input/test_clean.csv'\n",
    "PATH_SMPLE_SUB = './../data/input/sample_submission.csv'\n",
    "DIR_OUTPUT = './../data/output/'\n",
    "DIR_OUTPUT_IGNORE = './../data/output_ignore/'\n",
    "cp = ['#f8b195', '#f67280', '#c06c84', '#6c5b7b', '#355c7d']\n",
    "sr = 10*10**3  # 10 kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import os\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "# from pykalman import KalmanFilter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fastprogress import progress_bar\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "# from dtreeviz.trees import dtreeviz\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(true, pred):\n",
    "    return f1_score(true, pred, average='macro')\n",
    "\n",
    "def get_df_batch(df, batch):\n",
    "    idxs = df['batch'] == batch\n",
    "    assert any(idxs), 'そのようなbatchはありません'\n",
    "    return df[idxs]\n",
    "    \n",
    "def get_signal_mv_mean(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).mean().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "def get_signal_mv_std(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).std().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "def get_signal_mv_min(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).min().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "def get_signal_mv_max(df, n=3001):\n",
    "    signal_mv = np.zeros(len(df))\n",
    "    for bt in df['batch'].unique():\n",
    "        idxs = df['batch'] == bt\n",
    "        _signal_mv = df['signal'][idxs].rolling(n, center=True).max().interpolate('spline', order=5, limit_direction='both').values\n",
    "        signal_mv[idxs] = _signal_mv\n",
    "    return signal_mv\n",
    "\n",
    "\n",
    "\n",
    "def group_feat_train(_train):\n",
    "    train = _train.copy()\n",
    "    # group init\n",
    "    train['group'] = int(0)\n",
    "\n",
    "    # group 1\n",
    "    idxs = (train['batch'] == 3) | (train['batch'] == 7)\n",
    "    train['group'][idxs] = int(1)\n",
    "\n",
    "    # group 2\n",
    "    idxs = (train['batch'] == 5) | (train['batch'] == 8)\n",
    "    train['group'][idxs] = int(2)\n",
    "\n",
    "    # group 3\n",
    "    idxs = (train['batch'] == 2) | (train['batch'] == 6)\n",
    "    train['group'][idxs] = int(3)\n",
    "\n",
    "    # group 4\n",
    "    idxs = (train['batch'] == 4) | (train['batch'] == 9)\n",
    "    train['group'][idxs] = int(4)\n",
    "    \n",
    "    return train[['group']]\n",
    "\n",
    "def group_feat_test(_test):\n",
    "    test = _test.copy()\n",
    "    \n",
    "    # group init\n",
    "    test['group'] = int(0)\n",
    "    x_idx = np.arange(len(test))\n",
    "\n",
    "    # group 1\n",
    "    idxs = (100000<=x_idx) & (x_idx<200000)\n",
    "    test['group'][idxs] = int(1)\n",
    "    idxs = (900000<=x_idx) & (x_idx<=1000000)\n",
    "    test['group'][idxs] = int(1)\n",
    "\n",
    "    # group 2\n",
    "    idxs = (200000<=x_idx) & (x_idx<300000)\n",
    "    test['group'][idxs] = int(2)\n",
    "    idxs = (600000<=x_idx) & (x_idx<700000)\n",
    "    test['group'][idxs] = int(2)\n",
    "\n",
    "    # group 3\n",
    "    idxs = (400000<=x_idx) & (x_idx<500000)\n",
    "    test['group'][idxs] = int(3)\n",
    "\n",
    "    # group 4\n",
    "    idxs = (500000<=x_idx) & (x_idx<600000)\n",
    "    test['group'][idxs] = int(4)\n",
    "    idxs = (700000<=x_idx) & (x_idx<800000)\n",
    "    test['group'][idxs] = int(4)\n",
    "    \n",
    "    return test[['group']]\n",
    "\n",
    "\n",
    "class permutation_importance():\n",
    "    def __init__(self, model, metric):\n",
    "        self.is_computed = False\n",
    "        self.n_feat = 0\n",
    "        self.base_score = 0\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.df_result = []\n",
    "    \n",
    "    def compute(self, X_valid, y_valid):\n",
    "        self.n_feat = len(X_valid.columns)\n",
    "        if self.metric == 'auc':\n",
    "            y_valid_score = self.model.predict_proba(X_valid)[:, 1]\n",
    "            fpr, tpr, thresholds = roc_curve(y_valid, y_valid_score)\n",
    "            self.base_score = auc(fpr, tpr)\n",
    "        else:\n",
    "            pred = np.round(self.model.predict(X_valid)).astype('int8')\n",
    "            self.base_score = self.metric(y_valid, pred)\n",
    "        self.df_result = pd.DataFrame({'feat': X_valid.columns, \n",
    "                                       'score': np.zeros(self.n_feat),\n",
    "                                       'score_diff': np.zeros(self.n_feat)})\n",
    "        \n",
    "        # predict\n",
    "        for i, col in enumerate(X_valid.columns):\n",
    "            df_perm = X_valid.copy()\n",
    "            np.random.seed(1)\n",
    "            df_perm[col] = np.random.permutation(df_perm[col])\n",
    "            y_valid_pred = self.model.predict(df_perm)\n",
    "            if self.metric == 'auc':\n",
    "                y_valid_score = self.model.predict_proba(df_perm)[:, 1]\n",
    "                fpr, tpr, thresholds = roc_curve(y_valid, y_valid_score)\n",
    "                score = auc(fpr, tpr)\n",
    "            else:\n",
    "                score = self.metric(y_valid, np.round(y_valid_pred).astype('int8'))\n",
    "            self.df_result['score'][self.df_result['feat']==col] = score\n",
    "            self.df_result['score_diff'][self.df_result['feat']==col] = self.base_score - score\n",
    "        self.is_computed = True\n",
    "    \n",
    "    def get_negative_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] < 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "        \n",
    "    def get_positive_feature(self):\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        idx = self.df_result['score_diff'] > 0\n",
    "        return self.df_result.loc[idx, 'feat'].values.tolist()\n",
    "    \n",
    "    def show_permutation_importance(self, score_type='loss'):\n",
    "        '''score_type = 'loss' or 'accuracy'  '''\n",
    "        assert self.is_computed!=False, 'compute メソッドが実行されていません'\n",
    "        if score_type=='loss':\n",
    "            ascending = True\n",
    "        elif score_type=='accuracy':\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = ''\n",
    "        \n",
    "        plt.figure(figsize=(15, int(0.25*self.n_feat)))\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=self.df_result.sort_values(by=\"score_diff\", ascending=ascending))\n",
    "        plt.title('base_score - permutation_score')\n",
    "\n",
    "def plot_corr(df, abs_=False, threshold=0.95):\n",
    "    if abs_==True:\n",
    "        corr = df.corr().abs()>threshold\n",
    "        vmin = 0\n",
    "    else:\n",
    "        corr = df.corr()\n",
    "        vmin = -1\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), dpi=100)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    sns.heatmap(corr,\n",
    "                xticklabels=df.corr().columns,\n",
    "                yticklabels=df.corr().columns,\n",
    "                vmin=vmin,\n",
    "                vmax=1,\n",
    "                center=0, \n",
    "                annot=False)\n",
    "\n",
    "    # Decorations\n",
    "    ax.set_title('Correlation', fontsize=22)\n",
    "\n",
    "def get_low_corr_column(df, threshold):\n",
    "\n",
    "    df_corr = df.corr()\n",
    "    df_corr = abs(df_corr)\n",
    "    columns = df_corr.columns\n",
    "\n",
    "    # 対角線の値を0にする\n",
    "    for i in range(0, len(columns)):\n",
    "        df_corr.iloc[i, i] = 0\n",
    "\n",
    "    while True:\n",
    "        columns = df_corr.columns\n",
    "        max_corr = 0.0\n",
    "        query_column = None\n",
    "        target_column = None\n",
    "\n",
    "        df_max_column_value = df_corr.max()\n",
    "        max_corr = df_max_column_value.max()\n",
    "        query_column = df_max_column_value.idxmax()\n",
    "        target_column = df_corr[query_column].idxmax()\n",
    "\n",
    "        if max_corr < threshold:\n",
    "            # しきい値を超えるものがなかったため終了\n",
    "            break\n",
    "        else:\n",
    "            # しきい値を超えるものがあった場合\n",
    "            delete_column = None\n",
    "            saved_column = None\n",
    "\n",
    "            # その他との相関の絶対値が大きい方を除去\n",
    "            if sum(df_corr[query_column]) <= sum(df_corr[target_column]):\n",
    "                delete_column = target_column\n",
    "                saved_column = query_column\n",
    "            else:\n",
    "                delete_column = query_column\n",
    "                saved_column = target_column\n",
    "\n",
    "            # 除去すべき特徴を相関行列から消す（行、列）\n",
    "            df_corr.drop([delete_column], axis=0, inplace=True)\n",
    "            df_corr.drop([delete_column], axis=1, inplace=True)\n",
    "\n",
    "    return df_corr.columns  # 相関が高い特徴量を除いた名前リスト\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        if col!='open_channels':\n",
    "            col_type = df[col].dtypes\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def create_signal_mod(train):\n",
    "    left = 3641000\n",
    "    right = 3829000\n",
    "    thresh_dict = {\n",
    "        3: [0.1, 2.0],\n",
    "        2: [-1.1, 0.7],\n",
    "        1: [-2.3, -0.6],\n",
    "        0: [-3.8, -2],\n",
    "    }\n",
    "    \n",
    "    train['signal'] = train['signal'].values\n",
    "    for ch in train[train['batch']==7]['open_channels'].unique():\n",
    "        idxs_noisy = (train['open_channels']==ch) & (left<train.index) & (train.index<right)\n",
    "        idxs_not_noisy = (train['open_channels']==ch) & ~idxs_noisy\n",
    "        mean = train[idxs_not_noisy]['signal'].mean()\n",
    "\n",
    "        idxs_outlier = idxs_noisy & (thresh_dict[ch][1]<train['signal'].values)\n",
    "        train['signal'][idxs_outlier]  = mean\n",
    "        idxs_outlier = idxs_noisy & (train['signal'].values<thresh_dict[ch][0])\n",
    "        train['signal'][idxs_outlier]  = mean\n",
    "    return train\n",
    "\n",
    "def create_signal_mod2(train):\n",
    "    left = 3641000\n",
    "    right = 3829000\n",
    "    thresh_dict = {\n",
    "        3: [0.1, 2.0],\n",
    "        2: [-1.1, 0.7],\n",
    "        1: [-2.3, -0.6],\n",
    "        0: [-3.8, -2],\n",
    "    }\n",
    "    \n",
    "    train['signal'] = train['signal'].values\n",
    "    for ch in train[train['batch']==7]['open_channels'].unique():\n",
    "        idxs_noisy = (train['open_channels']==ch) & (left<train.index) & (train.index<right)\n",
    "        idxs_not_noisy = (train['open_channels']==ch) & ~idxs_noisy\n",
    "        mean = train[idxs_not_noisy]['signal'].mean()\n",
    "        std = train[idxs_not_noisy]['signal'].std()\n",
    "\n",
    "        idxs_outlier = idxs_noisy & (thresh_dict[ch][1]<train['signal'].values)\n",
    "        noise = np.random.normal(loc=0, scale=std, size=len(train['signal'].values[idxs_outlier]))\n",
    "        train['signal'][idxs_outlier]  = mean + noise\n",
    "        idxs_outlier = idxs_noisy & (train['signal'].values<thresh_dict[ch][0])\n",
    "        noise = np.random.normal(loc=0, scale=std, size=len(train['signal'].values[idxs_outlier]))\n",
    "        train['signal'][idxs_outlier]  = mean + noise\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(X, y, X_te, lgbm_params, random_state=5, n_fold=5, verbose=50, early_stopping_rounds=100, show_fig=True):\n",
    "    # using features\n",
    "    print(f'features({len(X.columns)}): \\n{X.columns}') if not verbose==0 else None\n",
    "\n",
    "#     folds = KFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "\n",
    "    scores = []\n",
    "    oof = np.zeros(len(X))\n",
    "    oof_round = np.zeros(len(X))\n",
    "    test_pred = np.zeros(len(X_te))\n",
    "    df_pi = pd.DataFrame(columns=['feat', 'score_diff'])\n",
    "    for fold_n, (train_idx, valid_idx) in enumerate(folds.split(X, y=y)):\n",
    "        if  verbose==0:\n",
    "            pass\n",
    "        else:\n",
    "            print('\\n------------------')\n",
    "            print(f'- Fold {fold_n + 1}/{N_FOLD} started at {time.ctime()}')\n",
    "\n",
    "        # prepare dataset\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        # train\n",
    "        model = LGBMRegressor(**lgbm_params, n_estimators=N_ESTIMATORS)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=verbose,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        # pred\n",
    "        y_valid_pred = model.predict(X_valid, model.best_iteration_)\n",
    "        y_valid_pred_round = np.round(y_valid_pred).astype('int8')\n",
    "        _test_pred = model.predict(X_te, model.best_iteration_)\n",
    "\n",
    "        if show_fig==False:\n",
    "            pass\n",
    "        else:\n",
    "            # permutation importance\n",
    "            pi = permutation_importance(model, f1_macro) # model と metric を渡す\n",
    "            pi.compute(X_valid, y_valid)\n",
    "            pi_result = pi.df_result\n",
    "            df_pi = pd.concat([df_pi, pi_result[['feat', 'score_diff']]])\n",
    "\n",
    "        # result\n",
    "        oof[valid_idx] = y_valid_pred\n",
    "        oof_round[valid_idx] = y_valid_pred_round\n",
    "        score = f1_score(y_valid, y_valid_pred_round, average='macro')\n",
    "        scores.append(score)\n",
    "        test_pred += _test_pred\n",
    "        if verbose==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'---> f1-score(macro) valid: {f1_score(y_valid, y_valid_pred_round, average=\"macro\"):.4f}')\n",
    "            print('')\n",
    "\n",
    "\n",
    "    print('====== finish ======')\n",
    "    print('score list:', scores)\n",
    "    print('CV mean score(f1_macro): {0:.4f}, std: {1:.4f}'.format(np.mean(scores), np.std(scores)))\n",
    "    print(f'oof score(f1_macro): {f1_score(y, oof_round, average=\"macro\"):.4f}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    if show_fig==False:\n",
    "        pass\n",
    "    else:\n",
    "        # visualization\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot([0, 10], [0, 10], color='gray')\n",
    "        plt.scatter(y, oof, alpha=0.05, color=cp[1])\n",
    "        plt.xlabel('true')\n",
    "        plt.ylabel('pred')\n",
    "        plt.show()\n",
    "          \n",
    "        # confusion_matrix\n",
    "        plot_confusion_matrix(y, oof_round, classes=np.arange(11))\n",
    "        \n",
    "        \n",
    "        # permutation importance\n",
    "        plt.figure(figsize=(15, int(0.25*len(X.columns))))\n",
    "        order = df_pi.groupby([\"feat\"]).mean()['score_diff'].reset_index().sort_values('score_diff', ascending=False)\n",
    "        sns.barplot(x=\"score_diff\", y=\"feat\", data=df_pi, order=order['feat'])\n",
    "        plt.title('base_score - permutation_score')\n",
    "        plt.show()\n",
    "\n",
    "    # submission\n",
    "    test_pred = test_pred/N_FOLD\n",
    "    test_pred_round = np.round(test_pred).astype('int8')\n",
    "      \n",
    "    return test_pred_round, test_pred, oof_round, oof\n",
    "\n",
    "def plot_confusion_matrix(truth, pred, classes, normalize=False, title=''):\n",
    "    cm = confusion_matrix(truth, pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix', size=15)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_lgbm(X, y, X_te, lgbm_params, random_state=5, test_size=0.3, verbose=50, early_stopping_rounds=100, show_fig=True):\n",
    "    # using features\n",
    "    print(f'features({len(X.columns)}): \\n{X.columns}') if not verbose==0 else None\n",
    "\n",
    "#     folds = KFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "#     folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # prepare dataset\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # train\n",
    "    model = LGBMRegressor(**lgbm_params, n_estimators=N_ESTIMATORS)\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              verbose=verbose,\n",
    "              early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    # pred\n",
    "    oof = model.predict(X_valid, model.best_iteration_)\n",
    "    oof_round = np.round(oof).astype('int8')\n",
    "    test_pred = model.predict(X_te, model.best_iteration_)\n",
    "    test_pred_round = np.round(test_pred).astype('int8')\n",
    "\n",
    "    print('====== finish ======')\n",
    "    print(f'oof score(f1_macro): {f1_score(y_valid, oof_round, average=\"macro\"):.4f}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    if show_fig==False:\n",
    "        pass\n",
    "    else:\n",
    "        # visualization\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot([0, 10], [0, 10], color='gray')\n",
    "        plt.scatter(y_valid, oof, alpha=0.05, color=cp[1])\n",
    "        plt.xlabel('true')\n",
    "        plt.ylabel('pred')\n",
    "        plt.show()\n",
    "          \n",
    "        # confusion_matrix\n",
    "        plot_confusion_matrix(y_valid, oof_round, classes=np.arange(11))\n",
    "        \n",
    "        # permutation importance\n",
    "        pi = permutation_importance(model, f1_macro) # model と metric を渡す\n",
    "        pi.compute(X_valid, y_valid)\n",
    "        pi.show_permutation_importance(score_type='accuracy')  # loss or accuracy\n",
    "        plt.show()\n",
    "\n",
    "    return test_pred_round, test_pred, oof_round, oof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "ref: https://www.kaggle.com/martxelo/fe-and-ensemble-mlp-and-lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradients(s, n_grads=4):\n",
    "    '''\n",
    "    Calculate gradients for a pandas series. Returns the same number of samples\n",
    "    '''\n",
    "    grads = pd.DataFrame()\n",
    "    \n",
    "    g = s.values\n",
    "    for i in range(n_grads):\n",
    "        g = np.gradient(g)\n",
    "        grads['grad_' + str(i+1)] = g\n",
    "        \n",
    "    return grads\n",
    "\n",
    "\n",
    "def calc_low_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies low pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.3, n_filts)\n",
    "#     wns = [0.3244]\n",
    "    \n",
    "    low_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='low')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return low_pass\n",
    "\n",
    "def calc_high_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies high pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.1, n_filts)\n",
    "#     wns = [0.0100, 0.0264, 0.0699, 0.3005, 0.4885, 0.7943]\n",
    "    \n",
    "    high_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='high')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return high_pass\n",
    "\n",
    "def calc_roll_stats(s, windows=[10, 50, 100, 500, 1000, 3000]):\n",
    "    '''\n",
    "    Calculates rolling stats like mean, std, min, max...\n",
    "    '''\n",
    "    roll_stats = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        roll_stats['roll_mean_' + str(w)] = s.rolling(window=w, min_periods=1).mean().interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_std_' + str(w)] = s.rolling(window=w, min_periods=1).std().interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_min_' + str(w)] = s.rolling(window=w, min_periods=1).min().interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_max_' + str(w)] = s.rolling(window=w, min_periods=1).max().interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_range_' + str(w)] = roll_stats['roll_max_' + str(w)] - roll_stats['roll_min_' + str(w)]\n",
    "        roll_stats['roll_q10_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.10).interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_q25_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.25).interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_q50_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.50).interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_q75_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.75).interpolate('spline', order=5, limit_direction='both')\n",
    "        roll_stats['roll_q90_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.90).interpolate('spline', order=5, limit_direction='both')\n",
    "    \n",
    "    # add zeros when na values (std)\n",
    "#     roll_stats = roll_stats.fillna(value=0)\n",
    "             \n",
    "    return roll_stats\n",
    "\n",
    "def calc_ewm(s, windows=[10, 50, 100, 500, 1000, 3000]):\n",
    "    '''\n",
    "    Calculates exponential weighted functions\n",
    "    '''\n",
    "    ewm = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n",
    "        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n",
    "        \n",
    "    # add zeros when na values (std)\n",
    "    ewm = ewm.fillna(value=0)\n",
    "        \n",
    "    return ewm\n",
    "\n",
    "\n",
    "\n",
    "def divide_and_add_features(s, signal_size=500000):\n",
    "    '''\n",
    "    Divide the signal in bags of \"signal_size\".\n",
    "    Normalize the data dividing it by 15.0\n",
    "    '''\n",
    "    # normalize\n",
    "    s = s/15.0\n",
    "    \n",
    "    ls = []\n",
    "    for i in progress_bar(range(int(s.shape[0]/signal_size))):\n",
    "        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n",
    "        sig_featured = add_features(sig)\n",
    "        ls.append(sig_featured)\n",
    "    \n",
    "    return pd.concat(ls, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "ref: https://www.kaggle.com/nxrprime/single-model-lgbm-kalman-filter-ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kalman1D(observations,damping=1):\n",
    "    # To return the smoothed time series data\n",
    "    observation_covariance = damping\n",
    "    initial_value_guess = observations[0]\n",
    "    transition_matrix = 1\n",
    "    transition_covariance = 0.1\n",
    "    initial_value_guess\n",
    "    kf = KalmanFilter(\n",
    "            initial_state_mean=initial_value_guess,\n",
    "            initial_state_covariance=observation_covariance,\n",
    "            observation_covariance=observation_covariance,\n",
    "            transition_covariance=transition_covariance,\n",
    "            transition_matrices=transition_matrix\n",
    "        )\n",
    "    pred_state, state_cov = kf.smooth(observations)\n",
    "    return pred_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_tr = pd.read_csv(PATH_TRAIN)\n",
    "df_te = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "処理のしやすさのために、バッチ番号を振る"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_list = []\n",
    "for n in range(10):\n",
    "    batchs = np.ones(500000)*n\n",
    "    batch_list.append(batchs.astype(int))\n",
    "batch_list = np.hstack(batch_list)\n",
    "df_tr['batch'] = batch_list\n",
    "\n",
    "batch_list = []\n",
    "for n in range(4):\n",
    "    batchs = np.ones(500000)*n\n",
    "    batch_list.append(batchs.astype(int))\n",
    "batch_list = np.hstack(batch_list)\n",
    "df_te['batch'] = batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "smallset?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if isSmallSet:\n",
    "    print('small set mode')\n",
    "    # train\n",
    "    batchs = df_tr['batch'].values\n",
    "    dfs = []\n",
    "    for i_bt, bt in enumerate(df_tr['batch'].unique()):\n",
    "        idxs = batchs == bt\n",
    "        _df = df_tr[idxs][:LENGTH].copy()\n",
    "        dfs.append(_df)\n",
    "    df_tr = pd.concat(dfs).reset_index(drop=True)\n",
    "    \n",
    "    # test\n",
    "    batchs = df_te['batch'].values\n",
    "    dfs = []\n",
    "    for i_bt, bt in enumerate(df_te['batch'].unique()):\n",
    "        idxs = batchs == bt\n",
    "        _df = df_te[idxs][:LENGTH].copy()\n",
    "        dfs.append(_df)\n",
    "    df_te = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations and main hyperparammeters\n",
    "# EPOCHS = 180\n",
    "EPOCHS = 180\n",
    "NNBATCHSIZE = 16\n",
    "GROUP_BATCH_SIZE = 4000\n",
    "SEED = 321\n",
    "LR = 0.0015\n",
    "SPLITS = 5\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "def read_data():\n",
    "    train = pd.read_csv(PATH_TRAIN, dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n",
    "    test  = pd.read_csv(PATH_TEST, dtype={'time': np.float32, 'signal': np.float32})\n",
    "    sub  = pd.read_csv(PATH_SMPLE_SUB, dtype={'time': np.float32})\n",
    "    \n",
    "#     Y_train_proba = np.load('./../data/input/Y_train_proba.npy')\n",
    "#     Y_test_proba = np.load('./../data/input/Y_test_proba.npy')\n",
    "    probas = np.load(PATH_PROBAS)\n",
    "    Y_train_proba = probas['arr_0']\n",
    "    Y_test_proba = probas['arr_1']\n",
    "    \n",
    "    for i in range(11):\n",
    "        train[f\"proba_{i}\"] = Y_train_proba[:, i]\n",
    "        test[f\"proba_{i}\"] = Y_test_proba[:, i]\n",
    "        \n",
    "\n",
    "    # add offset\n",
    "    batch_list = []\n",
    "    for n in range(10):\n",
    "        batchs = np.ones(500000)*n\n",
    "        batch_list.append(batchs.astype(int))\n",
    "    batch_list = np.hstack(batch_list)\n",
    "    train['batch'] = batch_list\n",
    "    batch_list = []\n",
    "    for n in range(4):\n",
    "        batchs = np.ones(500000)*n\n",
    "        batch_list.append(batchs.astype(int))\n",
    "    batch_list = np.hstack(batch_list)\n",
    "    test['batch'] = batch_list\n",
    "    \n",
    "    group = group_feat_train(train)\n",
    "    train = pd.concat([train, group], axis=1)\n",
    "    group = group_feat_test(test)\n",
    "    test = pd.concat([test, group], axis=1)\n",
    "    \n",
    "    off_set_4 = 0.952472 - (-1.766044)\n",
    "    off_set_9 = 0.952472 - (-1.770441)\n",
    "    # batch4\n",
    "    idxs = train['batch'] == 4\n",
    "    train['signal'][idxs] = train['signal'].values + off_set_4\n",
    "    # batch9\n",
    "    idxs = train['batch'] == 9\n",
    "    train['signal'][idxs] = train['signal'].values + off_set_9\n",
    "    \n",
    "    off_set_test = 2.750\n",
    "    # group4\n",
    "    idxs = test['group'] == 4\n",
    "    test['signal'][idxs] = test['signal'][idxs].values + off_set_test\n",
    "    \n",
    "    \n",
    "    # mod batch7\n",
    "    if MOD_BATCH7:\n",
    "        train = create_signal_mod2(train)\n",
    "    \n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot(train['signal'])\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot(test['signal'])\n",
    "    plt.show()\n",
    "    \n",
    "    train = train.drop(['batch', 'group'], axis=1)\n",
    "    test = test.drop(['batch', 'group'], axis=1)\n",
    "    return train, test, sub\n",
    "\n",
    "# create batches of 4000 observations\n",
    "def batching(df, batch_size):\n",
    "    df['group'] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n",
    "    df['group'] = df['group'].astype(np.uint16)\n",
    "    return df\n",
    "\n",
    "# normalize the data (standard scaler). We can also try other scalers for a better score!\n",
    "def normalize(train, test):\n",
    "    train_input_mean = train.signal.mean()\n",
    "    train_input_sigma = train.signal.std()\n",
    "    train['signal'] = (train.signal - train_input_mean) / train_input_sigma\n",
    "    test['signal'] = (test.signal - train_input_mean) / train_input_sigma\n",
    "    return train, test\n",
    "\n",
    "# get lead and lags features\n",
    "def lag_with_pct_change(df, windows):\n",
    "    for window in windows:    \n",
    "        df['signal_shift_pos_' + str(window)] = df.groupby('group')['signal'].shift(window).fillna(0)\n",
    "        df['signal_shift_neg_' + str(window)] = df.groupby('group')['signal'].shift(-1 * window).fillna(0)\n",
    "    return df\n",
    "\n",
    "def roll_stats(df, windows):\n",
    "    for w in windows:\n",
    "        df['roll_mean_' + str(w)] = df.groupby('group')['signal'].rolling(window=w, min_periods=1).mean().values\n",
    "        df['roll_std_' + str(w)] = df.groupby('group')['signal'].rolling(window=w, min_periods=1).std().values\n",
    "    return df\n",
    "\n",
    "# main module to run feature engineering. Here you may want to try and add other features and check if your score imporves :).\n",
    "def run_feat_engineering(df, batch_size):\n",
    "    # create batches\n",
    "    df = batching(df, batch_size = batch_size)\n",
    "    # create leads and lags (1, 2, 3 making them 6 features)\n",
    "    df = lag_with_pct_change(df, [1, 2, 3])\n",
    "    # create signal ** 2 (this is the new feature)\n",
    "    df['signal_2'] = df['signal'] ** 2\n",
    "    # roll_stats\n",
    "    if ROLL_FEATS:\n",
    "        df = roll_stats(df, [10, 300])\n",
    "    return df\n",
    "\n",
    "# fillna with the mean and select features for training\n",
    "def feature_selection(train, test):\n",
    "    features = [col for col in train.columns if col not in ['index', 'group', 'open_channels', 'time']]\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "    test = test.replace([np.inf, -np.inf], np.nan)\n",
    "    for feature in features:\n",
    "        feature_mean = pd.concat([train[feature], test[feature]], axis = 0).mean()\n",
    "        train[feature] = train[feature].fillna(feature_mean)\n",
    "        test[feature] = test[feature].fillna(feature_mean)\n",
    "    return train, test, features\n",
    "\n",
    "# model function (very important, you can try different arquitectures to get a better score. I believe that top public leaderboard is a 1D Conv + RNN style)\n",
    "def Classifier(shape_):\n",
    "    \n",
    "    def cbr(x, out_layer, kernel, stride, dilation):\n",
    "        x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        return x\n",
    "    \n",
    "    def wave_block(x, filters, kernel_size, n):\n",
    "        dilation_rates = [2**i for i in range(n)]\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = x\n",
    "        for dilation_rate in dilation_rates:\n",
    "            tanh_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same', \n",
    "                              activation = 'tanh', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            sigm_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same',\n",
    "                              activation = 'sigmoid', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            x = Multiply()([tanh_out, sigm_out])\n",
    "            x = Conv1D(filters = filters,\n",
    "                       kernel_size = 1,\n",
    "                       padding = 'same')(x)\n",
    "            res_x = Add()([res_x, x])\n",
    "        return res_x\n",
    "    \n",
    "    inp = Input(shape = (shape_))\n",
    "    x = cbr(inp, 64, 7, 1, 1)\n",
    "#     x = BatchNormalization()(x)  # 追加 (参考: https://www.kaggle.com/siavrez/wavenet-keras)\n",
    "#     x = wave_block(x, 8, 3, 18)  # 追加\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 16, 3, 12)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 32, 3, 8)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 128, 3, 1)\n",
    "    x = cbr(x, 32, 7, 1, 1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(11, activation = 'softmax', name = 'out')(x)\n",
    "    \n",
    "    model = models.Model(inputs = inp, outputs = out)\n",
    "    \n",
    "    opt = Adam(lr = LR)\n",
    "#     opt = tfa.optimizers.SWA(opt)\n",
    "#     model.compile(loss = losses.CategoricalCrossentropy(), optimizer = opt, metrics = ['accuracy'])\n",
    "    model.compile(loss = categorical_crossentropy, optimizer = opt, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# function that decrease the learning as epochs increase (i also change this part of the code)\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 30:\n",
    "        lr = LR\n",
    "    elif epoch < 40:\n",
    "        lr = LR / 3\n",
    "    elif epoch < 50:\n",
    "        lr = LR / 5\n",
    "    elif epoch < 60:\n",
    "        lr = LR / 7\n",
    "    elif epoch < 70:\n",
    "        lr = LR / 9\n",
    "    elif epoch < 80:\n",
    "        lr = LR / 11\n",
    "    elif epoch < 90:\n",
    "        lr = LR / 13\n",
    "    else:\n",
    "        lr = LR / 100\n",
    "    return lr\n",
    "\n",
    "# class to get macro f1 score. This is not entirely necessary but it's fun to check f1 score of each epoch (be carefull, if you use this function early stopping callback will not work)\n",
    "class MacroF1(Callback):\n",
    "    def __init__(self, model, inputs, targets):\n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis = 2).reshape(-1)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis = 2).reshape(-1)\n",
    "        score = f1_score(self.targets, pred, average = 'macro')\n",
    "        print(f'F1 Macro Score: {score:.5f}')\n",
    "\n",
    "# main function to perfrom groupkfold cross validation (we have 1000 vectores of 4000 rows and 8 features (columns)). Going to make 5 groups with this subgroups.\n",
    "def run_cv_model_by_batch(train, test, _splits, batch_col, feats, sample_submission, nn_epochs, nn_batch_size):\n",
    "    \n",
    "    seed_everything(SEED)\n",
    "    K.clear_session()\n",
    "#     config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1, \n",
    "#                                       gpu_options=tf.compat.v1.GPUOptions(\n",
    "#                                       visible_device_list='4', # specify GPU number\n",
    "#                                       allow_growth=True\n",
    "#                                       )\n",
    "#                                      )\n",
    "#     sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "#     tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # tf.compat.v1 ---> tf  (tensorflow2系からtensorflow1系に変更)\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1, \n",
    "#                                       gpu_options=tf.GPUOptions(\n",
    "#                                       visible_device_list='4', # specify GPU number\n",
    "#                                       allow_growth=True\n",
    "#                                       )\n",
    "                                     )\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
    "    tf.keras.backend.set_session(sess)\n",
    "    oof_ = np.zeros((len(train), 11)) # build out of folds matrix with 11 columns, they represent our target variables classes (from 0 to 10)\n",
    "    preds_ = np.zeros((len(test), 11))\n",
    "    target = ['open_channels']\n",
    "    group = train['group']\n",
    "    kf = GroupKFold(n_splits=_splits)\n",
    "    splits = [x for x in kf.split(train, train[target], group)]\n",
    "\n",
    "    new_splits = []\n",
    "    for sp in splits:\n",
    "        new_split = []\n",
    "        new_split.append(np.unique(group[sp[0]]))\n",
    "        new_split.append(np.unique(group[sp[1]]))\n",
    "        new_split.append(sp[1])    \n",
    "        new_splits.append(new_split)\n",
    "    # pivot target columns to transform the net to a multiclass classification estructure (you can also leave it in 1 vector with sparsecategoricalcrossentropy loss function)\n",
    "    tr = pd.concat([pd.get_dummies(train.open_channels), train[['group']]], axis=1)\n",
    "\n",
    "    tr.columns = ['target_'+str(i) for i in range(11)] + ['group']\n",
    "    target_cols = ['target_'+str(i) for i in range(11)]\n",
    "    train_tr = np.array(list(tr.groupby('group').apply(lambda x: x[target_cols].values))).astype(np.float32)\n",
    "    train = np.array(list(train.groupby('group').apply(lambda x: x[feats].values)))\n",
    "    test = np.array(list(test.groupby('group').apply(lambda x: x[feats].values)))\n",
    "\n",
    "    for n_fold, (tr_idx, val_idx, val_orig_idx) in enumerate(new_splits[0:], start=0):\n",
    "        train_x, train_y = train[tr_idx], train_tr[tr_idx]\n",
    "        valid_x, valid_y = train[val_idx], train_tr[val_idx]\n",
    "        print(f'Our training dataset shape is {train_x.shape}')\n",
    "        print(f'Our validation dataset shape is {valid_x.shape}')\n",
    "\n",
    "        gc.collect()\n",
    "        shape_ = (None, train_x.shape[2]) # input is going to be the number of feature we are using (dimension 2 of 0, 1, 2)\n",
    "        model = Classifier(shape_)\n",
    "        # using our lr_schedule function\n",
    "        cb_lr_schedule = LearningRateScheduler(lr_schedule)\n",
    "        model.fit(train_x,train_y,\n",
    "                  epochs = nn_epochs,\n",
    "                  callbacks = [cb_lr_schedule, MacroF1(model, valid_x, valid_y)], # adding custom evaluation metric for each epoch\n",
    "                  batch_size = nn_batch_size,verbose = 2,\n",
    "                  validation_data = (valid_x,valid_y))\n",
    "        preds_f = model.predict(valid_x)\n",
    "        f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  np.argmax(preds_f, axis=2).reshape(-1), average = 'macro') # need to get the class with the biggest probability\n",
    "        print(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n",
    "        preds_f = preds_f.reshape(-1, preds_f.shape[-1])\n",
    "        oof_[val_orig_idx,:] += preds_f\n",
    "        te_preds = model.predict(test)\n",
    "        te_preds = te_preds.reshape(-1, te_preds.shape[-1])           \n",
    "        preds_ += te_preds / _splits\n",
    "    # calculate the oof macro f1_score\n",
    "    f1_score_ = f1_score(np.argmax(train_tr, axis = 2).reshape(-1),  np.argmax(oof_, axis = 1), average = 'macro') # axis 2 for the 3 Dimension array and axis 1 for the 2 Domension Array (extracting the best class)\n",
    "    print(f'Training completed. oof macro f1 score : {f1_score_:1.5f}')\n",
    "    \n",
    "    # submission\n",
    "    save_path = f'{DIR_OUTPUT}submission_nb{NB}_cv_{f1_score_:.4f}.csv'\n",
    "    print(f'submission save path: {save_path}')\n",
    "    sample_submission['open_channels'] = np.argmax(preds_, axis = 1).astype(int)\n",
    "    sample_submission.to_csv(save_path, index=False, float_format='%.4f')\n",
    "    \n",
    "    # probas\n",
    "    save_path = f'{DIR_OUTPUT_IGNORE}probas_nb{NB}_cv_{f1_score_:.4f}'\n",
    "    print(f'probas save path: {save_path}')\n",
    "    np.savez_compressed(save_path, oof_, preds_)\n",
    "\n",
    "    return oof_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Started...(Mon May 18 20:13:09 2020)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Normalizing Data Completed\n",
      "Creating Features(Mon May 18 20:13:17 2020)\n",
      "Feature Engineering Started...\n",
      "Feature Engineering Completed...\n",
      "Training Wavenet model with 5 folds of GroupKFold Started...(Mon May 18 20:13:35 2020)\n",
      "Our training dataset shape is (1000, 4000, 23)\n",
      "Our validation dataset shape is (250, 4000, 23)\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/180\n",
      "F1 Macro Score: 0.74159\n",
      " - 22s - loss: 0.5538 - acc: 0.8471 - val_loss: 0.9127 - val_acc: 0.9112\n",
      "Epoch 2/180\n",
      "F1 Macro Score: 0.83833\n",
      " - 12s - loss: 0.1768 - acc: 0.9600 - val_loss: 0.4814 - val_acc: 0.9503\n",
      "Epoch 3/180\n",
      "F1 Macro Score: 0.92942\n",
      " - 12s - loss: 0.1323 - acc: 0.9675 - val_loss: 0.2360 - val_acc: 0.9660\n",
      "Epoch 4/180\n",
      "F1 Macro Score: 0.93746\n",
      " - 12s - loss: 0.1209 - acc: 0.9685 - val_loss: 0.1414 - val_acc: 0.9684\n",
      "Epoch 5/180\n",
      "F1 Macro Score: 0.94034\n",
      " - 12s - loss: 0.1146 - acc: 0.9689 - val_loss: 0.1204 - val_acc: 0.9694\n",
      "Epoch 6/180\n",
      "F1 Macro Score: 0.93935\n",
      " - 12s - loss: 0.1122 - acc: 0.9691 - val_loss: 0.1035 - val_acc: 0.9691\n",
      "Epoch 7/180\n",
      "F1 Macro Score: 0.94042\n",
      " - 12s - loss: 0.1081 - acc: 0.9693 - val_loss: 0.1011 - val_acc: 0.9694\n",
      "Epoch 8/180\n",
      "F1 Macro Score: 0.94058\n",
      " - 12s - loss: 0.1045 - acc: 0.9696 - val_loss: 0.0955 - val_acc: 0.9696\n",
      "Epoch 9/180\n",
      "F1 Macro Score: 0.93665\n",
      " - 12s - loss: 0.1028 - acc: 0.9696 - val_loss: 0.1066 - val_acc: 0.9673\n",
      "Epoch 10/180\n",
      "F1 Macro Score: 0.93784\n",
      " - 12s - loss: 0.1031 - acc: 0.9692 - val_loss: 0.1199 - val_acc: 0.9681\n",
      "Epoch 11/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.1197 - acc: 0.9673 - val_loss: 0.1000 - val_acc: 0.9693\n",
      "Epoch 12/180\n",
      "F1 Macro Score: 0.92916\n",
      " - 12s - loss: 0.1071 - acc: 0.9692 - val_loss: 0.1065 - val_acc: 0.9659\n",
      "Epoch 13/180\n",
      "F1 Macro Score: 0.94042\n",
      " - 12s - loss: 0.1004 - acc: 0.9697 - val_loss: 0.0929 - val_acc: 0.9697\n",
      "Epoch 14/180\n",
      "F1 Macro Score: 0.93727\n",
      " - 12s - loss: 0.1004 - acc: 0.9696 - val_loss: 0.1016 - val_acc: 0.9677\n",
      "Epoch 15/180\n",
      "F1 Macro Score: 0.94082\n",
      " - 12s - loss: 0.0970 - acc: 0.9699 - val_loss: 0.0919 - val_acc: 0.9697\n",
      "Epoch 16/180\n",
      "F1 Macro Score: 0.87280\n",
      " - 12s - loss: 0.1833 - acc: 0.9456 - val_loss: 0.1702 - val_acc: 0.9480\n",
      "Epoch 17/180\n",
      "F1 Macro Score: 0.93280\n",
      " - 12s - loss: 0.1088 - acc: 0.9689 - val_loss: 0.1116 - val_acc: 0.9675\n",
      "Epoch 18/180\n",
      "F1 Macro Score: 0.93893\n",
      " - 12s - loss: 0.1038 - acc: 0.9694 - val_loss: 0.0972 - val_acc: 0.9691\n",
      "Epoch 19/180\n",
      "F1 Macro Score: 0.94015\n",
      " - 12s - loss: 0.1032 - acc: 0.9694 - val_loss: 0.0947 - val_acc: 0.9692\n",
      "Epoch 20/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0997 - acc: 0.9698 - val_loss: 0.0906 - val_acc: 0.9699\n",
      "Epoch 21/180\n",
      "F1 Macro Score: 0.94104\n",
      " - 12s - loss: 0.0994 - acc: 0.9697 - val_loss: 0.0918 - val_acc: 0.9697\n",
      "Epoch 22/180\n",
      "F1 Macro Score: 0.94012\n",
      " - 12s - loss: 0.0972 - acc: 0.9699 - val_loss: 0.0919 - val_acc: 0.9695\n",
      "Epoch 23/180\n",
      "F1 Macro Score: 0.93835\n",
      " - 12s - loss: 0.0958 - acc: 0.9700 - val_loss: 0.0965 - val_acc: 0.9682\n",
      "Epoch 24/180\n",
      "F1 Macro Score: 0.93886\n",
      " - 12s - loss: 0.0944 - acc: 0.9701 - val_loss: 0.0945 - val_acc: 0.9684\n",
      "Epoch 25/180\n",
      "F1 Macro Score: 0.94052\n",
      " - 12s - loss: 0.0944 - acc: 0.9700 - val_loss: 0.0901 - val_acc: 0.9696\n",
      "Epoch 26/180\n",
      "F1 Macro Score: 0.93961\n",
      " - 12s - loss: 0.0944 - acc: 0.9700 - val_loss: 0.0895 - val_acc: 0.9697\n",
      "Epoch 27/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0949 - acc: 0.9698 - val_loss: 0.0877 - val_acc: 0.9699\n",
      "Epoch 28/180\n",
      "F1 Macro Score: 0.93605\n",
      " - 12s - loss: 0.0926 - acc: 0.9701 - val_loss: 0.0930 - val_acc: 0.9688\n",
      "Epoch 29/180\n",
      "F1 Macro Score: 0.94126\n",
      " - 12s - loss: 0.0917 - acc: 0.9701 - val_loss: 0.0870 - val_acc: 0.9699\n",
      "Epoch 30/180\n",
      "F1 Macro Score: 0.94088\n",
      " - 12s - loss: 0.0911 - acc: 0.9701 - val_loss: 0.0871 - val_acc: 0.9697\n",
      "Epoch 31/180\n",
      "F1 Macro Score: 0.94007\n",
      " - 12s - loss: 0.0908 - acc: 0.9702 - val_loss: 0.0889 - val_acc: 0.9692\n",
      "Epoch 32/180\n",
      "F1 Macro Score: 0.94150\n",
      " - 12s - loss: 0.0896 - acc: 0.9703 - val_loss: 0.0856 - val_acc: 0.9699\n",
      "Epoch 33/180\n",
      "F1 Macro Score: 0.94132\n",
      " - 12s - loss: 0.0888 - acc: 0.9704 - val_loss: 0.0853 - val_acc: 0.9699\n",
      "Epoch 34/180\n",
      "F1 Macro Score: 0.94150\n",
      " - 12s - loss: 0.0890 - acc: 0.9703 - val_loss: 0.0850 - val_acc: 0.9699\n",
      "Epoch 35/180\n",
      "F1 Macro Score: 0.94074\n",
      " - 12s - loss: 0.0890 - acc: 0.9703 - val_loss: 0.0864 - val_acc: 0.9695\n",
      "Epoch 36/180\n",
      "F1 Macro Score: 0.94162\n",
      " - 12s - loss: 0.0887 - acc: 0.9703 - val_loss: 0.0847 - val_acc: 0.9701\n",
      "Epoch 37/180\n",
      "F1 Macro Score: 0.94170\n",
      " - 12s - loss: 0.0891 - acc: 0.9703 - val_loss: 0.0844 - val_acc: 0.9700\n",
      "Epoch 38/180\n",
      "F1 Macro Score: 0.93946\n",
      " - 12s - loss: 0.0878 - acc: 0.9704 - val_loss: 0.0887 - val_acc: 0.9688\n",
      "Epoch 39/180\n",
      "F1 Macro Score: 0.94099\n",
      " - 12s - loss: 0.0905 - acc: 0.9699 - val_loss: 0.0858 - val_acc: 0.9696\n",
      "Epoch 40/180\n",
      "F1 Macro Score: 0.94159\n",
      " - 12s - loss: 0.0883 - acc: 0.9703 - val_loss: 0.0843 - val_acc: 0.9700\n",
      "Epoch 41/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0882 - acc: 0.9703 - val_loss: 0.0841 - val_acc: 0.9700\n",
      "Epoch 42/180\n",
      "F1 Macro Score: 0.94136\n",
      " - 12s - loss: 0.0870 - acc: 0.9704 - val_loss: 0.0843 - val_acc: 0.9699\n",
      "Epoch 43/180\n",
      "F1 Macro Score: 0.94102\n",
      " - 12s - loss: 0.0876 - acc: 0.9703 - val_loss: 0.0844 - val_acc: 0.9699\n",
      "Epoch 44/180\n",
      "F1 Macro Score: 0.94123\n",
      " - 12s - loss: 0.0872 - acc: 0.9703 - val_loss: 0.0845 - val_acc: 0.9698\n",
      "Epoch 45/180\n",
      "F1 Macro Score: 0.94168\n",
      " - 12s - loss: 0.0873 - acc: 0.9703 - val_loss: 0.0838 - val_acc: 0.9700\n",
      "Epoch 46/180\n",
      "F1 Macro Score: 0.94168\n",
      " - 12s - loss: 0.0874 - acc: 0.9703 - val_loss: 0.0835 - val_acc: 0.9700\n",
      "Epoch 47/180\n",
      "F1 Macro Score: 0.94139\n",
      " - 12s - loss: 0.0869 - acc: 0.9703 - val_loss: 0.0839 - val_acc: 0.9699\n",
      "Epoch 48/180\n",
      "F1 Macro Score: 0.94133\n",
      " - 12s - loss: 0.0870 - acc: 0.9703 - val_loss: 0.0836 - val_acc: 0.9699\n",
      "Epoch 49/180\n",
      "F1 Macro Score: 0.94055\n",
      " - 12s - loss: 0.0868 - acc: 0.9703 - val_loss: 0.0855 - val_acc: 0.9695\n",
      "Epoch 50/180\n",
      "F1 Macro Score: 0.94140\n",
      " - 12s - loss: 0.0865 - acc: 0.9704 - val_loss: 0.0834 - val_acc: 0.9699\n",
      "Epoch 51/180\n",
      "F1 Macro Score: 0.94176\n",
      " - 12s - loss: 0.0868 - acc: 0.9704 - val_loss: 0.0831 - val_acc: 0.9701\n",
      "Epoch 52/180\n",
      "F1 Macro Score: 0.94170\n",
      " - 12s - loss: 0.0858 - acc: 0.9704 - val_loss: 0.0832 - val_acc: 0.9700\n",
      "Epoch 53/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0861 - acc: 0.9705 - val_loss: 0.0833 - val_acc: 0.9700\n",
      "Epoch 54/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0865 - acc: 0.9704 - val_loss: 0.0832 - val_acc: 0.9699\n",
      "Epoch 55/180\n",
      "F1 Macro Score: 0.94115\n",
      " - 12s - loss: 0.0863 - acc: 0.9704 - val_loss: 0.0836 - val_acc: 0.9698\n",
      "Epoch 56/180\n",
      "F1 Macro Score: 0.94097\n",
      " - 12s - loss: 0.0862 - acc: 0.9703 - val_loss: 0.0838 - val_acc: 0.9697\n",
      "Epoch 57/180\n",
      "F1 Macro Score: 0.94133\n",
      " - 12s - loss: 0.0856 - acc: 0.9704 - val_loss: 0.0832 - val_acc: 0.9699\n",
      "Epoch 58/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0856 - acc: 0.9704 - val_loss: 0.0832 - val_acc: 0.9699\n",
      "Epoch 59/180\n",
      "F1 Macro Score: 0.94113\n",
      " - 12s - loss: 0.0871 - acc: 0.9699 - val_loss: 0.0838 - val_acc: 0.9698\n",
      "Epoch 60/180\n",
      "F1 Macro Score: 0.94090\n",
      " - 12s - loss: 0.0883 - acc: 0.9701 - val_loss: 0.0851 - val_acc: 0.9696\n",
      "Epoch 61/180\n",
      "F1 Macro Score: 0.94097\n",
      " - 12s - loss: 0.0859 - acc: 0.9704 - val_loss: 0.0840 - val_acc: 0.9696\n",
      "Epoch 62/180\n",
      "F1 Macro Score: 0.94182\n",
      " - 12s - loss: 0.0863 - acc: 0.9704 - val_loss: 0.0826 - val_acc: 0.9701\n",
      "Epoch 63/180\n",
      "F1 Macro Score: 0.94160\n",
      " - 12s - loss: 0.0856 - acc: 0.9704 - val_loss: 0.0827 - val_acc: 0.9701\n",
      "Epoch 64/180\n",
      "F1 Macro Score: 0.94131\n",
      " - 12s - loss: 0.0851 - acc: 0.9705 - val_loss: 0.0831 - val_acc: 0.9698\n",
      "Epoch 65/180\n",
      "F1 Macro Score: 0.94117\n",
      " - 12s - loss: 0.0854 - acc: 0.9704 - val_loss: 0.0839 - val_acc: 0.9697\n",
      "Epoch 66/180\n",
      "F1 Macro Score: 0.94145\n",
      " - 12s - loss: 0.0844 - acc: 0.9705 - val_loss: 0.0826 - val_acc: 0.9699\n",
      "Epoch 67/180\n",
      "F1 Macro Score: 0.94121\n",
      " - 12s - loss: 0.0854 - acc: 0.9703 - val_loss: 0.0836 - val_acc: 0.9698\n",
      "Epoch 68/180\n",
      "F1 Macro Score: 0.94135\n",
      " - 12s - loss: 0.0851 - acc: 0.9704 - val_loss: 0.0826 - val_acc: 0.9699\n",
      "Epoch 69/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0848 - acc: 0.9704 - val_loss: 0.0823 - val_acc: 0.9699\n",
      "Epoch 70/180\n",
      "F1 Macro Score: 0.94144\n",
      " - 12s - loss: 0.0851 - acc: 0.9704 - val_loss: 0.0824 - val_acc: 0.9699\n",
      "Epoch 71/180\n",
      "F1 Macro Score: 0.94136\n",
      " - 12s - loss: 0.0847 - acc: 0.9704 - val_loss: 0.0823 - val_acc: 0.9699\n",
      "Epoch 72/180\n",
      "F1 Macro Score: 0.94140\n",
      " - 12s - loss: 0.0848 - acc: 0.9704 - val_loss: 0.0824 - val_acc: 0.9699\n",
      "Epoch 73/180\n",
      "F1 Macro Score: 0.94150\n",
      " - 12s - loss: 0.0847 - acc: 0.9704 - val_loss: 0.0821 - val_acc: 0.9700\n",
      "Epoch 74/180\n",
      "F1 Macro Score: 0.94131\n",
      " - 12s - loss: 0.0842 - acc: 0.9705 - val_loss: 0.0824 - val_acc: 0.9699\n",
      "Epoch 75/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0848 - acc: 0.9704 - val_loss: 0.0823 - val_acc: 0.9699\n",
      "Epoch 76/180\n",
      "F1 Macro Score: 0.94169\n",
      " - 12s - loss: 0.0842 - acc: 0.9705 - val_loss: 0.0817 - val_acc: 0.9701\n",
      "Epoch 77/180\n",
      "F1 Macro Score: 0.94120\n",
      " - 12s - loss: 0.0842 - acc: 0.9705 - val_loss: 0.0825 - val_acc: 0.9698\n",
      "Epoch 78/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0840 - acc: 0.9705 - val_loss: 0.0821 - val_acc: 0.9699\n",
      "Epoch 79/180\n",
      "F1 Macro Score: 0.94145\n",
      " - 12s - loss: 0.0839 - acc: 0.9705 - val_loss: 0.0819 - val_acc: 0.9699\n",
      "Epoch 80/180\n",
      "F1 Macro Score: 0.94108\n",
      " - 12s - loss: 0.0835 - acc: 0.9705 - val_loss: 0.0825 - val_acc: 0.9698\n",
      "Epoch 81/180\n",
      "F1 Macro Score: 0.94153\n",
      " - 12s - loss: 0.0832 - acc: 0.9705 - val_loss: 0.0817 - val_acc: 0.9700\n",
      "Epoch 82/180\n",
      "F1 Macro Score: 0.94160\n",
      " - 12s - loss: 0.0843 - acc: 0.9705 - val_loss: 0.0818 - val_acc: 0.9700\n",
      "Epoch 83/180\n",
      "F1 Macro Score: 0.94164\n",
      " - 12s - loss: 0.0835 - acc: 0.9705 - val_loss: 0.0817 - val_acc: 0.9700\n",
      "Epoch 84/180\n",
      "F1 Macro Score: 0.94020\n",
      " - 12s - loss: 0.0840 - acc: 0.9705 - val_loss: 0.0841 - val_acc: 0.9693\n",
      "Epoch 85/180\n",
      "F1 Macro Score: 0.94149\n",
      " - 12s - loss: 0.0836 - acc: 0.9704 - val_loss: 0.0817 - val_acc: 0.9700\n",
      "Epoch 86/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0834 - acc: 0.9705 - val_loss: 0.0817 - val_acc: 0.9699\n",
      "Epoch 87/180\n",
      "F1 Macro Score: 0.94142\n",
      " - 12s - loss: 0.0840 - acc: 0.9704 - val_loss: 0.0817 - val_acc: 0.9699\n",
      "Epoch 88/180\n",
      "F1 Macro Score: 0.94141\n",
      " - 12s - loss: 0.0834 - acc: 0.9705 - val_loss: 0.0817 - val_acc: 0.9699\n",
      "Epoch 89/180\n",
      "F1 Macro Score: 0.94093\n",
      " - 12s - loss: 0.0830 - acc: 0.9706 - val_loss: 0.0823 - val_acc: 0.9696\n",
      "Epoch 90/180\n",
      "F1 Macro Score: 0.94153\n",
      " - 12s - loss: 0.0832 - acc: 0.9705 - val_loss: 0.0815 - val_acc: 0.9700\n",
      "Epoch 91/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0829 - acc: 0.9705 - val_loss: 0.0813 - val_acc: 0.9700\n",
      "Epoch 92/180\n",
      "F1 Macro Score: 0.94162\n",
      " - 12s - loss: 0.0826 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 93/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0826 - acc: 0.9706 - val_loss: 0.0813 - val_acc: 0.9700\n",
      "Epoch 94/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0829 - acc: 0.9706 - val_loss: 0.0813 - val_acc: 0.9700\n",
      "Epoch 95/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0827 - acc: 0.9707 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 96/180\n",
      "F1 Macro Score: 0.94125\n",
      " - 12s - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0817 - val_acc: 0.9698\n",
      "Epoch 97/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0813 - val_acc: 0.9700\n",
      "Epoch 98/180\n",
      "F1 Macro Score: 0.94140\n",
      " - 12s - loss: 0.0830 - acc: 0.9706 - val_loss: 0.0815 - val_acc: 0.9699\n",
      "Epoch 99/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0823 - acc: 0.9707 - val_loss: 0.0813 - val_acc: 0.9700\n",
      "Epoch 100/180\n",
      "F1 Macro Score: 0.94163\n",
      " - 12s - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 101/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0828 - acc: 0.9707 - val_loss: 0.0814 - val_acc: 0.9700\n",
      "Epoch 102/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0830 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 103/180\n",
      "F1 Macro Score: 0.94171\n",
      " - 12s - loss: 0.0831 - acc: 0.9705 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 104/180\n",
      "F1 Macro Score: 0.94166\n",
      " - 12s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 105/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0823 - acc: 0.9707 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 106/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 107/180\n",
      "F1 Macro Score: 0.94164\n",
      " - 12s - loss: 0.0825 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 108/180\n",
      "F1 Macro Score: 0.94165\n",
      " - 12s - loss: 0.0827 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 109/180\n",
      "F1 Macro Score: 0.94153\n",
      " - 12s - loss: 0.0824 - acc: 0.9707 - val_loss: 0.0813 - val_acc: 0.9699\n",
      "Epoch 110/180\n",
      "F1 Macro Score: 0.94132\n",
      " - 12s - loss: 0.0827 - acc: 0.9706 - val_loss: 0.0814 - val_acc: 0.9699\n",
      "Epoch 111/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0825 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 112/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 113/180\n",
      "F1 Macro Score: 0.94162\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 114/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0825 - acc: 0.9707 - val_loss: 0.0813 - val_acc: 0.9699\n",
      "Epoch 115/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 116/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0823 - acc: 0.9707 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 117/180\n",
      "F1 Macro Score: 0.94160\n",
      " - 12s - loss: 0.0826 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 118/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0823 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 119/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0827 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 120/180\n",
      "F1 Macro Score: 0.94168\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 121/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0826 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 122/180\n",
      "F1 Macro Score: 0.94149\n",
      " - 12s - loss: 0.0821 - acc: 0.9707 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 123/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0830 - acc: 0.9705 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 124/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0826 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 125/180\n",
      "F1 Macro Score: 0.94139\n",
      " - 12s - loss: 0.0825 - acc: 0.9707 - val_loss: 0.0813 - val_acc: 0.9699\n",
      "Epoch 126/180\n",
      "F1 Macro Score: 0.94150\n",
      " - 12s - loss: 0.0825 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9700\n",
      "Epoch 127/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0825 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 128/180\n",
      "F1 Macro Score: 0.94151\n",
      " - 12s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 129/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0826 - acc: 0.9706 - val_loss: 0.0813 - val_acc: 0.9699\n",
      "Epoch 130/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0822 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 131/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0823 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 132/180\n",
      "F1 Macro Score: 0.94149\n",
      " - 12s - loss: 0.0822 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 133/180\n",
      "F1 Macro Score: 0.94121\n",
      " - 12s - loss: 0.0822 - acc: 0.9707 - val_loss: 0.0816 - val_acc: 0.9698\n",
      "Epoch 134/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0821 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 135/180\n",
      "F1 Macro Score: 0.94162\n",
      " - 12s - loss: 0.0828 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 136/180\n",
      "F1 Macro Score: 0.94151\n",
      " - 12s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9700\n",
      "Epoch 137/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0822 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 138/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0822 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 139/180\n",
      "F1 Macro Score: 0.94162\n",
      " - 12s - loss: 0.0823 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 140/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0821 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 141/180\n",
      "F1 Macro Score: 0.94156\n",
      " - 12s - loss: 0.0821 - acc: 0.9707 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 142/180\n",
      "F1 Macro Score: 0.94159\n",
      " - 12s - loss: 0.0820 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 143/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0822 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 144/180\n",
      "F1 Macro Score: 0.94166\n",
      " - 12s - loss: 0.0820 - acc: 0.9707 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 145/180\n",
      "F1 Macro Score: 0.94148\n",
      " - 12s - loss: 0.0825 - acc: 0.9705 - val_loss: 0.0811 - val_acc: 0.9699\n",
      "Epoch 146/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0820 - acc: 0.9707 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 147/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0820 - acc: 0.9706 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 148/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0822 - acc: 0.9707 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 149/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0812 - val_acc: 0.9699\n",
      "Epoch 150/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0819 - acc: 0.9706 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 151/180\n",
      "F1 Macro Score: 0.94144\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0811 - val_acc: 0.9699\n",
      "Epoch 152/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0820 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 153/180\n",
      "F1 Macro Score: 0.94122\n",
      " - 12s - loss: 0.0823 - acc: 0.9706 - val_loss: 0.0813 - val_acc: 0.9698\n",
      "Epoch 154/180\n",
      "F1 Macro Score: 0.94153\n",
      " - 12s - loss: 0.0818 - acc: 0.9706 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 155/180\n",
      "F1 Macro Score: 0.94159\n",
      " - 12s - loss: 0.0824 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 156/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0821 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9699\n",
      "Epoch 157/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0822 - acc: 0.9706 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 158/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0820 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 159/180\n",
      "F1 Macro Score: 0.94152\n",
      " - 12s - loss: 0.0817 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9700\n",
      "Epoch 160/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0818 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 161/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0817 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 162/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0823 - acc: 0.9706 - val_loss: 0.0808 - val_acc: 0.9700\n",
      "Epoch 163/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 164/180\n",
      "F1 Macro Score: 0.94148\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0811 - val_acc: 0.9699\n",
      "Epoch 165/180\n",
      "F1 Macro Score: 0.94143\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0811 - val_acc: 0.9699\n",
      "Epoch 166/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0818 - acc: 0.9707 - val_loss: 0.0808 - val_acc: 0.9700\n",
      "Epoch 167/180\n",
      "F1 Macro Score: 0.94150\n",
      " - 12s - loss: 0.0818 - acc: 0.9707 - val_loss: 0.0809 - val_acc: 0.9699\n",
      "Epoch 168/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0818 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 169/180\n",
      "F1 Macro Score: 0.94138\n",
      " - 12s - loss: 0.0817 - acc: 0.9706 - val_loss: 0.0811 - val_acc: 0.9699\n",
      "Epoch 170/180\n",
      "F1 Macro Score: 0.94134\n",
      " - 12s - loss: 0.0818 - acc: 0.9706 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 171/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0827 - acc: 0.9705 - val_loss: 0.0809 - val_acc: 0.9700\n",
      "Epoch 172/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0816 - acc: 0.9707 - val_loss: 0.0808 - val_acc: 0.9700\n",
      "Epoch 173/180\n",
      "F1 Macro Score: 0.94149\n",
      " - 12s - loss: 0.0817 - acc: 0.9707 - val_loss: 0.0809 - val_acc: 0.9699\n",
      "Epoch 174/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0819 - acc: 0.9706 - val_loss: 0.0808 - val_acc: 0.9700\n",
      "Epoch 175/180\n",
      "F1 Macro Score: 0.94140\n",
      " - 12s - loss: 0.0819 - acc: 0.9707 - val_loss: 0.0808 - val_acc: 0.9699\n",
      "Epoch 176/180\n",
      "F1 Macro Score: 0.94154\n",
      " - 12s - loss: 0.0815 - acc: 0.9707 - val_loss: 0.0808 - val_acc: 0.9700\n",
      "Epoch 177/180\n",
      "F1 Macro Score: 0.94155\n",
      " - 12s - loss: 0.0816 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9699\n",
      "Epoch 178/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0820 - acc: 0.9706 - val_loss: 0.0807 - val_acc: 0.9700\n",
      "Epoch 179/180\n",
      "F1 Macro Score: 0.94149\n",
      " - 12s - loss: 0.0815 - acc: 0.9707 - val_loss: 0.0808 - val_acc: 0.9700\n",
      "Epoch 180/180\n",
      "F1 Macro Score: 0.94147\n",
      " - 12s - loss: 0.0822 - acc: 0.9706 - val_loss: 0.0809 - val_acc: 0.9699\n",
      "Training fold 1 completed. macro f1 score : 0.94147\n",
      "Our training dataset shape is (1000, 4000, 23)\n",
      "Our validation dataset shape is (250, 4000, 23)\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/180\n",
      "F1 Macro Score: 0.89732\n",
      " - 19s - loss: 0.4878 - acc: 0.8647 - val_loss: 0.8854 - val_acc: 0.9454\n",
      "Epoch 2/180\n",
      "F1 Macro Score: 0.92898\n",
      " - 12s - loss: 0.1635 - acc: 0.9638 - val_loss: 0.4270 - val_acc: 0.9668\n",
      "Epoch 3/180\n",
      "F1 Macro Score: 0.94091\n",
      " - 12s - loss: 0.1315 - acc: 0.9676 - val_loss: 0.1829 - val_acc: 0.9711\n",
      "Epoch 4/180\n",
      "F1 Macro Score: 0.93986\n",
      " - 12s - loss: 0.1198 - acc: 0.9684 - val_loss: 0.1223 - val_acc: 0.9711\n",
      "Epoch 5/180\n",
      "F1 Macro Score: 0.94170\n",
      " - 12s - loss: 0.1154 - acc: 0.9685 - val_loss: 0.1021 - val_acc: 0.9714\n",
      "Epoch 6/180\n",
      "F1 Macro Score: 0.94121\n",
      " - 12s - loss: 0.1095 - acc: 0.9688 - val_loss: 0.0953 - val_acc: 0.9713\n",
      "Epoch 7/180\n",
      "F1 Macro Score: 0.94002\n",
      " - 12s - loss: 0.1062 - acc: 0.9690 - val_loss: 0.0936 - val_acc: 0.9709\n",
      "Epoch 8/180\n",
      "F1 Macro Score: 0.93889\n",
      " - 12s - loss: 0.1138 - acc: 0.9679 - val_loss: 0.0958 - val_acc: 0.9705\n",
      "Epoch 9/180\n",
      "F1 Macro Score: 0.94038\n",
      " - 12s - loss: 0.1043 - acc: 0.9690 - val_loss: 0.0903 - val_acc: 0.9710\n",
      "Epoch 10/180\n",
      "F1 Macro Score: 0.94069\n",
      " - 12s - loss: 0.1054 - acc: 0.9687 - val_loss: 0.0917 - val_acc: 0.9710\n",
      "Epoch 11/180\n",
      "F1 Macro Score: 0.93951\n",
      " - 12s - loss: 0.1021 - acc: 0.9690 - val_loss: 0.0905 - val_acc: 0.9708\n",
      "Epoch 12/180\n",
      "F1 Macro Score: 0.94092\n",
      " - 12s - loss: 0.0994 - acc: 0.9692 - val_loss: 0.0865 - val_acc: 0.9713\n",
      "Epoch 13/180\n",
      "F1 Macro Score: 0.94116\n",
      " - 12s - loss: 0.0979 - acc: 0.9692 - val_loss: 0.0864 - val_acc: 0.9712\n",
      "Epoch 14/180\n",
      "F1 Macro Score: 0.93962\n",
      " - 12s - loss: 0.0976 - acc: 0.9692 - val_loss: 0.0879 - val_acc: 0.9708\n",
      "Epoch 15/180\n",
      "F1 Macro Score: 0.93826\n",
      " - 12s - loss: 0.0957 - acc: 0.9693 - val_loss: 0.0916 - val_acc: 0.9705\n",
      "Epoch 16/180\n",
      "F1 Macro Score: 0.94117\n",
      " - 12s - loss: 0.0972 - acc: 0.9691 - val_loss: 0.0845 - val_acc: 0.9713\n",
      "Epoch 17/180\n",
      "F1 Macro Score: 0.93990\n",
      " - 12s - loss: 0.0958 - acc: 0.9691 - val_loss: 0.0854 - val_acc: 0.9709\n",
      "Epoch 18/180\n",
      "F1 Macro Score: 0.94150\n",
      " - 12s - loss: 0.0940 - acc: 0.9693 - val_loss: 0.0831 - val_acc: 0.9714\n",
      "Epoch 19/180\n",
      "F1 Macro Score: 0.94134\n",
      " - 12s - loss: 0.0928 - acc: 0.9693 - val_loss: 0.0832 - val_acc: 0.9715\n",
      "Epoch 20/180\n",
      "F1 Macro Score: 0.94158\n",
      " - 12s - loss: 0.0935 - acc: 0.9691 - val_loss: 0.0826 - val_acc: 0.9715\n",
      "Epoch 21/180\n",
      "F1 Macro Score: 0.93981\n",
      " - 12s - loss: 0.0937 - acc: 0.9692 - val_loss: 0.0870 - val_acc: 0.9706\n",
      "Epoch 22/180\n",
      "F1 Macro Score: 0.94007\n",
      " - 12s - loss: 0.1064 - acc: 0.9675 - val_loss: 0.0888 - val_acc: 0.9709\n",
      "Epoch 23/180\n",
      "F1 Macro Score: 0.94196\n",
      " - 12s - loss: 0.0954 - acc: 0.9693 - val_loss: 0.0822 - val_acc: 0.9716\n",
      "Epoch 24/180\n",
      "F1 Macro Score: 0.94246\n",
      " - 12s - loss: 0.0918 - acc: 0.9694 - val_loss: 0.0798 - val_acc: 0.9719\n",
      "Epoch 25/180\n",
      "F1 Macro Score: 0.93797\n",
      " - 12s - loss: 0.0930 - acc: 0.9692 - val_loss: 0.0897 - val_acc: 0.9698\n",
      "Epoch 26/180\n",
      "F1 Macro Score: 0.94011\n",
      " - 12s - loss: 0.0912 - acc: 0.9693 - val_loss: 0.0845 - val_acc: 0.9709\n",
      "Epoch 27/180\n",
      "F1 Macro Score: 0.94090\n",
      " - 12s - loss: 0.0900 - acc: 0.9695 - val_loss: 0.0807 - val_acc: 0.9713\n",
      "Epoch 28/180\n",
      "F1 Macro Score: 0.93963\n",
      " - 12s - loss: 0.0895 - acc: 0.9694 - val_loss: 0.0829 - val_acc: 0.9708\n",
      "Epoch 29/180\n",
      "F1 Macro Score: 0.94205\n",
      " - 12s - loss: 0.0898 - acc: 0.9694 - val_loss: 0.0791 - val_acc: 0.9718\n",
      "Epoch 30/180\n",
      "F1 Macro Score: 0.92463\n",
      " - 12s - loss: 0.0921 - acc: 0.9689 - val_loss: 0.1124 - val_acc: 0.9653\n",
      "Epoch 31/180\n",
      "F1 Macro Score: 0.94040\n",
      " - 12s - loss: 0.0947 - acc: 0.9691 - val_loss: 0.0809 - val_acc: 0.9716\n",
      "Epoch 32/180\n",
      "F1 Macro Score: 0.94189\n",
      " - 12s - loss: 0.0880 - acc: 0.9697 - val_loss: 0.0784 - val_acc: 0.9717\n",
      "Epoch 33/180\n",
      "F1 Macro Score: 0.94191\n",
      " - 12s - loss: 0.0872 - acc: 0.9697 - val_loss: 0.0780 - val_acc: 0.9718\n",
      "Epoch 34/180\n",
      "F1 Macro Score: 0.94223\n",
      " - 12s - loss: 0.0873 - acc: 0.9697 - val_loss: 0.0776 - val_acc: 0.9718\n",
      "Epoch 35/180\n",
      "F1 Macro Score: 0.94115\n",
      " - 12s - loss: 0.0860 - acc: 0.9697 - val_loss: 0.0785 - val_acc: 0.9715\n",
      "Epoch 36/180\n",
      "F1 Macro Score: 0.94238\n",
      " - 12s - loss: 0.0858 - acc: 0.9697 - val_loss: 0.0771 - val_acc: 0.9718\n",
      "Epoch 37/180\n",
      "F1 Macro Score: 0.94146\n",
      " - 12s - loss: 0.0862 - acc: 0.9696 - val_loss: 0.0787 - val_acc: 0.9715\n",
      "Epoch 38/180\n",
      "F1 Macro Score: 0.94108\n",
      " - 12s - loss: 0.0857 - acc: 0.9696 - val_loss: 0.0792 - val_acc: 0.9714\n",
      "Epoch 39/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0847 - acc: 0.9698 - val_loss: 0.0780 - val_acc: 0.9715\n",
      "Epoch 40/180\n",
      "F1 Macro Score: 0.94174\n",
      " - 12s - loss: 0.0854 - acc: 0.9696 - val_loss: 0.0772 - val_acc: 0.9717\n",
      "Epoch 41/180\n",
      "F1 Macro Score: 0.94212\n",
      " - 12s - loss: 0.0849 - acc: 0.9697 - val_loss: 0.0765 - val_acc: 0.9718\n",
      "Epoch 42/180\n",
      "F1 Macro Score: 0.94238\n",
      " - 12s - loss: 0.0842 - acc: 0.9698 - val_loss: 0.0764 - val_acc: 0.9719\n",
      "Epoch 43/180\n",
      "F1 Macro Score: 0.94236\n",
      " - 12s - loss: 0.0843 - acc: 0.9697 - val_loss: 0.0763 - val_acc: 0.9719\n",
      "Epoch 44/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0841 - acc: 0.9698 - val_loss: 0.0766 - val_acc: 0.9717\n",
      "Epoch 45/180\n",
      "F1 Macro Score: 0.94229\n",
      " - 12s - loss: 0.0843 - acc: 0.9698 - val_loss: 0.0764 - val_acc: 0.9718\n",
      "Epoch 46/180\n",
      "F1 Macro Score: 0.94186\n",
      " - 12s - loss: 0.0843 - acc: 0.9697 - val_loss: 0.0769 - val_acc: 0.9716\n",
      "Epoch 47/180\n",
      "F1 Macro Score: 0.94118\n",
      " - 12s - loss: 0.0836 - acc: 0.9698 - val_loss: 0.0779 - val_acc: 0.9714\n",
      "Epoch 48/180\n",
      "F1 Macro Score: 0.94220\n",
      " - 12s - loss: 0.0836 - acc: 0.9698 - val_loss: 0.0762 - val_acc: 0.9719\n",
      "Epoch 49/180\n",
      "F1 Macro Score: 0.94240\n",
      " - 12s - loss: 0.0836 - acc: 0.9698 - val_loss: 0.0763 - val_acc: 0.9719\n",
      "Epoch 50/180\n",
      "F1 Macro Score: 0.94221\n",
      " - 12s - loss: 0.0837 - acc: 0.9699 - val_loss: 0.0765 - val_acc: 0.9718\n",
      "Epoch 51/180\n",
      "F1 Macro Score: 0.94227\n",
      " - 12s - loss: 0.0833 - acc: 0.9699 - val_loss: 0.0761 - val_acc: 0.9718\n",
      "Epoch 52/180\n",
      "F1 Macro Score: 0.94195\n",
      " - 12s - loss: 0.0828 - acc: 0.9699 - val_loss: 0.0762 - val_acc: 0.9717\n",
      "Epoch 53/180\n",
      "F1 Macro Score: 0.94197\n",
      " - 12s - loss: 0.0826 - acc: 0.9699 - val_loss: 0.0760 - val_acc: 0.9717\n",
      "Epoch 54/180\n",
      "F1 Macro Score: 0.94207\n",
      " - 12s - loss: 0.0832 - acc: 0.9699 - val_loss: 0.0761 - val_acc: 0.9717\n",
      "Epoch 55/180\n",
      "F1 Macro Score: 0.94107\n",
      " - 12s - loss: 0.0832 - acc: 0.9698 - val_loss: 0.0785 - val_acc: 0.9712\n",
      "Epoch 56/180\n",
      "F1 Macro Score: 0.94223\n",
      " - 12s - loss: 0.0831 - acc: 0.9699 - val_loss: 0.0760 - val_acc: 0.9718\n",
      "Epoch 57/180\n",
      "F1 Macro Score: 0.94231\n",
      " - 12s - loss: 0.0827 - acc: 0.9699 - val_loss: 0.0764 - val_acc: 0.9718\n",
      "Epoch 58/180\n",
      "F1 Macro Score: 0.94216\n",
      " - 12s - loss: 0.0826 - acc: 0.9700 - val_loss: 0.0759 - val_acc: 0.9718\n",
      "Epoch 59/180\n",
      "F1 Macro Score: 0.94227\n",
      " - 12s - loss: 0.0827 - acc: 0.9700 - val_loss: 0.0762 - val_acc: 0.9718\n",
      "Epoch 60/180\n",
      "F1 Macro Score: 0.94174\n",
      " - 12s - loss: 0.0830 - acc: 0.9700 - val_loss: 0.0764 - val_acc: 0.9717\n",
      "Epoch 61/180\n",
      "F1 Macro Score: 0.94220\n",
      " - 12s - loss: 0.0819 - acc: 0.9701 - val_loss: 0.0757 - val_acc: 0.9718\n",
      "Epoch 62/180\n",
      "F1 Macro Score: 0.94215\n",
      " - 12s - loss: 0.0816 - acc: 0.9701 - val_loss: 0.0758 - val_acc: 0.9717\n",
      "Epoch 63/180\n",
      "F1 Macro Score: 0.94176\n",
      " - 12s - loss: 0.0819 - acc: 0.9700 - val_loss: 0.0761 - val_acc: 0.9716\n",
      "Epoch 64/180\n",
      "F1 Macro Score: 0.94209\n",
      " - 12s - loss: 0.0818 - acc: 0.9701 - val_loss: 0.0758 - val_acc: 0.9718\n",
      "Epoch 65/180\n",
      "F1 Macro Score: 0.94175\n",
      " - 12s - loss: 0.0817 - acc: 0.9701 - val_loss: 0.0763 - val_acc: 0.9715\n",
      "Epoch 66/180\n",
      "F1 Macro Score: 0.94196\n",
      " - 12s - loss: 0.0817 - acc: 0.9702 - val_loss: 0.0758 - val_acc: 0.9717\n",
      "Epoch 67/180\n",
      "F1 Macro Score: 0.94208\n",
      " - 12s - loss: 0.0816 - acc: 0.9702 - val_loss: 0.0760 - val_acc: 0.9718\n",
      "Epoch 68/180\n",
      "F1 Macro Score: 0.94142\n",
      " - 12s - loss: 0.0821 - acc: 0.9701 - val_loss: 0.0770 - val_acc: 0.9713\n",
      "Epoch 69/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0815 - acc: 0.9701 - val_loss: 0.0760 - val_acc: 0.9716\n",
      "Epoch 70/180\n",
      "F1 Macro Score: 0.94229\n",
      " - 12s - loss: 0.0817 - acc: 0.9701 - val_loss: 0.0757 - val_acc: 0.9718\n",
      "Epoch 71/180\n",
      "F1 Macro Score: 0.94169\n",
      " - 12s - loss: 0.0812 - acc: 0.9701 - val_loss: 0.0763 - val_acc: 0.9715\n",
      "Epoch 72/180\n",
      "F1 Macro Score: 0.94173\n",
      " - 12s - loss: 0.0814 - acc: 0.9702 - val_loss: 0.0767 - val_acc: 0.9715\n",
      "Epoch 73/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0811 - acc: 0.9703 - val_loss: 0.0761 - val_acc: 0.9716\n",
      "Epoch 74/180\n",
      "F1 Macro Score: 0.94179\n",
      " - 12s - loss: 0.0813 - acc: 0.9702 - val_loss: 0.0763 - val_acc: 0.9715\n",
      "Epoch 75/180\n",
      "F1 Macro Score: 0.94095\n",
      " - 12s - loss: 0.0812 - acc: 0.9702 - val_loss: 0.0769 - val_acc: 0.9713\n",
      "Epoch 76/180\n",
      "F1 Macro Score: 0.94181\n",
      " - 12s - loss: 0.0808 - acc: 0.9702 - val_loss: 0.0759 - val_acc: 0.9716\n",
      "Epoch 77/180\n",
      "F1 Macro Score: 0.94176\n",
      " - 12s - loss: 0.0808 - acc: 0.9703 - val_loss: 0.0762 - val_acc: 0.9716\n",
      "Epoch 78/180\n",
      "F1 Macro Score: 0.94168\n",
      " - 12s - loss: 0.0810 - acc: 0.9702 - val_loss: 0.0759 - val_acc: 0.9716\n",
      "Epoch 79/180\n",
      "F1 Macro Score: 0.94214\n",
      " - 12s - loss: 0.0805 - acc: 0.9703 - val_loss: 0.0756 - val_acc: 0.9717\n",
      "Epoch 80/180\n",
      "F1 Macro Score: 0.94143\n",
      " - 12s - loss: 0.0809 - acc: 0.9703 - val_loss: 0.0762 - val_acc: 0.9715\n",
      "Epoch 81/180\n",
      "F1 Macro Score: 0.94201\n",
      " - 12s - loss: 0.0804 - acc: 0.9703 - val_loss: 0.0758 - val_acc: 0.9717\n",
      "Epoch 82/180\n",
      "F1 Macro Score: 0.94171\n",
      " - 12s - loss: 0.0801 - acc: 0.9704 - val_loss: 0.0758 - val_acc: 0.9716\n",
      "Epoch 83/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0799 - acc: 0.9704 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 84/180\n",
      "F1 Macro Score: 0.94138\n",
      " - 12s - loss: 0.0805 - acc: 0.9704 - val_loss: 0.0762 - val_acc: 0.9715\n",
      "Epoch 85/180\n",
      "F1 Macro Score: 0.94167\n",
      " - 12s - loss: 0.0802 - acc: 0.9704 - val_loss: 0.0758 - val_acc: 0.9716\n",
      "Epoch 86/180\n",
      "F1 Macro Score: 0.94177\n",
      " - 12s - loss: 0.0808 - acc: 0.9703 - val_loss: 0.0759 - val_acc: 0.9716\n",
      "Epoch 87/180\n",
      "F1 Macro Score: 0.94136\n",
      " - 12s - loss: 0.0800 - acc: 0.9705 - val_loss: 0.0760 - val_acc: 0.9716\n",
      "Epoch 88/180\n",
      "F1 Macro Score: 0.94178\n",
      " - 12s - loss: 0.0799 - acc: 0.9704 - val_loss: 0.0757 - val_acc: 0.9717\n",
      "Epoch 89/180\n",
      "F1 Macro Score: 0.94187\n",
      " - 12s - loss: 0.0800 - acc: 0.9704 - val_loss: 0.0758 - val_acc: 0.9716\n",
      "Epoch 90/180\n",
      "F1 Macro Score: 0.94172\n",
      " - 12s - loss: 0.0798 - acc: 0.9705 - val_loss: 0.0758 - val_acc: 0.9716\n",
      "Epoch 91/180\n",
      "F1 Macro Score: 0.94180\n",
      " - 12s - loss: 0.0795 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9717\n",
      "Epoch 92/180\n",
      "F1 Macro Score: 0.94200\n",
      " - 12s - loss: 0.0794 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 93/180\n",
      "F1 Macro Score: 0.94186\n",
      " - 12s - loss: 0.0794 - acc: 0.9705 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 94/180\n",
      "F1 Macro Score: 0.94195\n",
      " - 12s - loss: 0.0794 - acc: 0.9705 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 95/180\n",
      "F1 Macro Score: 0.94204\n",
      " - 12s - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 96/180\n",
      "F1 Macro Score: 0.94197\n",
      " - 12s - loss: 0.0791 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 97/180\n",
      "F1 Macro Score: 0.94199\n",
      " - 12s - loss: 0.0790 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 98/180\n",
      "F1 Macro Score: 0.94195\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 99/180\n",
      "F1 Macro Score: 0.94185\n",
      " - 12s - loss: 0.0790 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 100/180\n",
      "F1 Macro Score: 0.94194\n",
      " - 12s - loss: 0.0791 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 101/180\n",
      "F1 Macro Score: 0.94185\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 102/180\n",
      "F1 Macro Score: 0.94195\n",
      " - 12s - loss: 0.0791 - acc: 0.9705 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 103/180\n",
      "F1 Macro Score: 0.94182\n",
      " - 12s - loss: 0.0794 - acc: 0.9706 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 104/180\n",
      "F1 Macro Score: 0.94193\n",
      " - 12s - loss: 0.0789 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 105/180\n",
      "F1 Macro Score: 0.94187\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 106/180\n",
      "F1 Macro Score: 0.94192\n",
      " - 12s - loss: 0.0790 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 107/180\n",
      "F1 Macro Score: 0.94175\n",
      " - 12s - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 108/180\n",
      "F1 Macro Score: 0.94192\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 109/180\n",
      "F1 Macro Score: 0.94194\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 110/180\n",
      "F1 Macro Score: 0.94191\n",
      " - 12s - loss: 0.0791 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9717\n",
      "Epoch 111/180\n",
      "F1 Macro Score: 0.94194\n",
      " - 12s - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 112/180\n",
      "F1 Macro Score: 0.94172\n",
      " - 12s - loss: 0.0791 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 113/180\n",
      "F1 Macro Score: 0.94173\n",
      " - 12s - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 114/180\n",
      "F1 Macro Score: 0.94198\n",
      " - 12s - loss: 0.0789 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9717\n",
      "Epoch 115/180\n",
      "F1 Macro Score: 0.94195\n",
      " - 12s - loss: 0.0793 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 116/180\n",
      "F1 Macro Score: 0.94165\n",
      " - 12s - loss: 0.0789 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 117/180\n",
      "F1 Macro Score: 0.94196\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 118/180\n",
      "F1 Macro Score: 0.94166\n",
      " - 12s - loss: 0.0789 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 119/180\n",
      "F1 Macro Score: 0.94196\n",
      " - 12s - loss: 0.0790 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 120/180\n",
      "F1 Macro Score: 0.94188\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 121/180\n",
      "F1 Macro Score: 0.94190\n",
      " - 12s - loss: 0.0787 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 122/180\n",
      "F1 Macro Score: 0.94194\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 123/180\n",
      "F1 Macro Score: 0.94200\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 124/180\n",
      "F1 Macro Score: 0.94187\n",
      " - 12s - loss: 0.0790 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 125/180\n",
      "F1 Macro Score: 0.94192\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 126/180\n",
      "F1 Macro Score: 0.94202\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 127/180\n",
      "F1 Macro Score: 0.94187\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 128/180\n",
      "F1 Macro Score: 0.94182\n",
      " - 12s - loss: 0.0785 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 129/180\n",
      "F1 Macro Score: 0.94194\n",
      " - 12s - loss: 0.0786 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 130/180\n",
      "F1 Macro Score: 0.94174\n",
      " - 12s - loss: 0.0789 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 131/180\n",
      "F1 Macro Score: 0.94176\n",
      " - 12s - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 132/180\n",
      "F1 Macro Score: 0.94180\n",
      " - 12s - loss: 0.0793 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 133/180\n",
      "F1 Macro Score: 0.94191\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 134/180\n",
      "F1 Macro Score: 0.94180\n",
      " - 12s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 135/180\n",
      "F1 Macro Score: 0.94186\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 136/180\n",
      "F1 Macro Score: 0.94180\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 137/180\n",
      "F1 Macro Score: 0.94176\n",
      " - 12s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 138/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 139/180\n",
      "F1 Macro Score: 0.94185\n",
      " - 12s - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 140/180\n",
      "F1 Macro Score: 0.94157\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0758 - val_acc: 0.9715\n",
      "Epoch 141/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 142/180\n",
      "F1 Macro Score: 0.94182\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 143/180\n",
      "F1 Macro Score: 0.94186\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 144/180\n",
      "F1 Macro Score: 0.94168\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 145/180\n",
      "F1 Macro Score: 0.94171\n",
      " - 12s - loss: 0.0786 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 146/180\n",
      "F1 Macro Score: 0.94183\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 147/180\n",
      "F1 Macro Score: 0.94167\n",
      " - 12s - loss: 0.0784 - acc: 0.9708 - val_loss: 0.0755 - val_acc: 0.9715\n",
      "Epoch 148/180\n",
      "F1 Macro Score: 0.94174\n",
      " - 12s - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 149/180\n",
      "F1 Macro Score: 0.94179\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 150/180\n",
      "F1 Macro Score: 0.94182\n",
      " - 12s - loss: 0.0787 - acc: 0.9706 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 151/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 152/180\n",
      "F1 Macro Score: 0.94182\n",
      " - 12s - loss: 0.0786 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 153/180\n",
      "F1 Macro Score: 0.94177\n",
      " - 12s - loss: 0.0787 - acc: 0.9706 - val_loss: 0.0755 - val_acc: 0.9716\n",
      "Epoch 154/180\n",
      "F1 Macro Score: 0.94183\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 155/180\n",
      "F1 Macro Score: 0.94167\n",
      " - 12s - loss: 0.0783 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 156/180\n",
      "F1 Macro Score: 0.94170\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 157/180\n",
      "F1 Macro Score: 0.94179\n",
      " - 12s - loss: 0.0784 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 158/180\n",
      "F1 Macro Score: 0.94181\n",
      " - 12s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 159/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9715\n",
      "Epoch 160/180\n",
      "F1 Macro Score: 0.94183\n",
      " - 12s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 161/180\n",
      "F1 Macro Score: 0.94181\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 162/180\n",
      "F1 Macro Score: 0.94161\n",
      " - 12s - loss: 0.0782 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9715\n",
      "Epoch 163/180\n",
      "F1 Macro Score: 0.94170\n",
      " - 12s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 164/180\n",
      "F1 Macro Score: 0.94176\n",
      " - 12s - loss: 0.0782 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 165/180\n",
      "F1 Macro Score: 0.94174\n",
      " - 12s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 166/180\n",
      "F1 Macro Score: 0.94170\n",
      " - 12s - loss: 0.0786 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 167/180\n",
      "F1 Macro Score: 0.94178\n",
      " - 12s - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 168/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 169/180\n",
      "F1 Macro Score: 0.94175\n",
      " - 12s - loss: 0.0780 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 170/180\n",
      "F1 Macro Score: 0.94173\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 171/180\n",
      "F1 Macro Score: 0.94185\n",
      " - 12s - loss: 0.0784 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 172/180\n",
      "F1 Macro Score: 0.94184\n",
      " - 12s - loss: 0.0781 - acc: 0.9707 - val_loss: 0.0757 - val_acc: 0.9715\n",
      "Epoch 173/180\n",
      "F1 Macro Score: 0.94178\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 174/180\n",
      "F1 Macro Score: 0.94159\n",
      " - 12s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0757 - val_acc: 0.9715\n",
      "Epoch 175/180\n",
      "F1 Macro Score: 0.94174\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 176/180\n",
      "F1 Macro Score: 0.94164\n",
      " - 12s - loss: 0.0783 - acc: 0.9707 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Epoch 177/180\n",
      "F1 Macro Score: 0.94175\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0757 - val_acc: 0.9716\n",
      "Epoch 178/180\n",
      "F1 Macro Score: 0.94173\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0757 - val_acc: 0.9715\n",
      "Epoch 179/180\n",
      "F1 Macro Score: 0.94179\n",
      " - 12s - loss: 0.0781 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9716\n",
      "Epoch 180/180\n",
      "F1 Macro Score: 0.94178\n",
      " - 12s - loss: 0.0781 - acc: 0.9708 - val_loss: 0.0756 - val_acc: 0.9715\n",
      "Training fold 2 completed. macro f1 score : 0.94178\n",
      "Our training dataset shape is (1000, 4000, 23)\n",
      "Our validation dataset shape is (250, 4000, 23)\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/180\n",
      "F1 Macro Score: 0.54872\n",
      " - 20s - loss: 0.5454 - acc: 0.8451 - val_loss: 0.9315 - val_acc: 0.7222\n",
      "Epoch 2/180\n",
      "F1 Macro Score: 0.84438\n",
      " - 12s - loss: 0.1675 - acc: 0.9611 - val_loss: 0.4821 - val_acc: 0.9245\n",
      "Epoch 3/180\n",
      "F1 Macro Score: 0.93313\n",
      " - 12s - loss: 0.1420 - acc: 0.9655 - val_loss: 0.2030 - val_acc: 0.9687\n",
      "Epoch 4/180\n",
      "F1 Macro Score: 0.93677\n",
      " - 12s - loss: 0.1193 - acc: 0.9685 - val_loss: 0.1284 - val_acc: 0.9695\n",
      "Epoch 5/180\n",
      "F1 Macro Score: 0.93565\n",
      " - 12s - loss: 0.1111 - acc: 0.9691 - val_loss: 0.1138 - val_acc: 0.9691\n",
      "Epoch 6/180\n",
      "F1 Macro Score: 0.93690\n",
      " - 12s - loss: 0.1095 - acc: 0.9692 - val_loss: 0.1038 - val_acc: 0.9698\n",
      "Epoch 7/180\n",
      "F1 Macro Score: 0.93380\n",
      " - 12s - loss: 0.1100 - acc: 0.9689 - val_loss: 0.1109 - val_acc: 0.9684\n",
      "Epoch 8/180\n",
      "F1 Macro Score: 0.93671\n",
      " - 12s - loss: 0.1051 - acc: 0.9693 - val_loss: 0.1013 - val_acc: 0.9696\n",
      "Epoch 9/180\n",
      "F1 Macro Score: 0.93841\n",
      " - 12s - loss: 0.1038 - acc: 0.9693 - val_loss: 0.0916 - val_acc: 0.9705\n",
      "Epoch 10/180\n",
      "F1 Macro Score: 0.93864\n",
      " - 12s - loss: 0.1015 - acc: 0.9694 - val_loss: 0.0911 - val_acc: 0.9706\n",
      "Epoch 11/180\n",
      "F1 Macro Score: 0.93830\n",
      " - 12s - loss: 0.0993 - acc: 0.9695 - val_loss: 0.0895 - val_acc: 0.9703\n",
      "Epoch 12/180\n",
      "F1 Macro Score: 0.93909\n",
      " - 12s - loss: 0.0982 - acc: 0.9695 - val_loss: 0.0876 - val_acc: 0.9708\n",
      "Epoch 13/180\n",
      "F1 Macro Score: 0.93780\n",
      " - 12s - loss: 0.0978 - acc: 0.9694 - val_loss: 0.0898 - val_acc: 0.9706\n",
      "Epoch 14/180\n",
      "F1 Macro Score: 0.93791\n",
      " - 12s - loss: 0.0957 - acc: 0.9695 - val_loss: 0.0888 - val_acc: 0.9702\n",
      "Epoch 15/180\n",
      "F1 Macro Score: 0.93810\n",
      " - 12s - loss: 0.0967 - acc: 0.9693 - val_loss: 0.0897 - val_acc: 0.9704\n",
      "Epoch 16/180\n",
      "F1 Macro Score: 0.93803\n",
      " - 12s - loss: 0.0940 - acc: 0.9696 - val_loss: 0.0881 - val_acc: 0.9702\n",
      "Epoch 17/180\n",
      "F1 Macro Score: 0.93773\n",
      " - 12s - loss: 0.0942 - acc: 0.9694 - val_loss: 0.0886 - val_acc: 0.9701\n",
      "Epoch 18/180\n",
      "F1 Macro Score: 0.93819\n",
      " - 12s - loss: 0.0936 - acc: 0.9695 - val_loss: 0.0861 - val_acc: 0.9703\n",
      "Epoch 19/180\n",
      "F1 Macro Score: 0.93807\n",
      " - 12s - loss: 0.0920 - acc: 0.9696 - val_loss: 0.0863 - val_acc: 0.9703\n",
      "Epoch 20/180\n",
      "F1 Macro Score: 0.93837\n",
      " - 12s - loss: 0.0938 - acc: 0.9694 - val_loss: 0.0872 - val_acc: 0.9705\n",
      "Epoch 21/180\n",
      "F1 Macro Score: 0.93669\n",
      " - 12s - loss: 0.0996 - acc: 0.9689 - val_loss: 0.0936 - val_acc: 0.9694\n",
      "Epoch 22/180\n",
      "F1 Macro Score: 0.93812\n",
      " - 12s - loss: 0.0991 - acc: 0.9689 - val_loss: 0.0901 - val_acc: 0.9704\n",
      "Epoch 23/180\n",
      "F1 Macro Score: 0.93819\n",
      " - 12s - loss: 0.0937 - acc: 0.9695 - val_loss: 0.0865 - val_acc: 0.9703\n",
      "Epoch 24/180\n",
      "F1 Macro Score: 0.93529\n",
      " - 12s - loss: 0.0913 - acc: 0.9696 - val_loss: 0.0954 - val_acc: 0.9688\n",
      "Epoch 25/180\n",
      "F1 Macro Score: 0.93667\n",
      " - 12s - loss: 0.0912 - acc: 0.9696 - val_loss: 0.0886 - val_acc: 0.9701\n",
      "Epoch 26/180\n",
      "F1 Macro Score: 0.93833\n",
      " - 12s - loss: 0.0910 - acc: 0.9696 - val_loss: 0.0844 - val_acc: 0.9705\n",
      "Epoch 27/180\n",
      "F1 Macro Score: 0.93826\n",
      " - 12s - loss: 0.0889 - acc: 0.9697 - val_loss: 0.0835 - val_acc: 0.9704\n",
      "Epoch 28/180\n",
      "F1 Macro Score: 0.93818\n",
      " - 12s - loss: 0.0881 - acc: 0.9697 - val_loss: 0.0834 - val_acc: 0.9704\n",
      "Epoch 29/180\n",
      "F1 Macro Score: 0.93856\n",
      " - 12s - loss: 0.0878 - acc: 0.9698 - val_loss: 0.0836 - val_acc: 0.9704\n",
      "Epoch 30/180\n",
      "F1 Macro Score: 0.93915\n",
      " - 12s - loss: 0.0896 - acc: 0.9696 - val_loss: 0.0820 - val_acc: 0.9708\n",
      "Epoch 31/180\n",
      "F1 Macro Score: 0.93875\n",
      " - 12s - loss: 0.0859 - acc: 0.9700 - val_loss: 0.0817 - val_acc: 0.9706\n",
      "Epoch 32/180\n",
      "F1 Macro Score: 0.93842\n",
      " - 12s - loss: 0.0854 - acc: 0.9700 - val_loss: 0.0814 - val_acc: 0.9706\n",
      "Epoch 33/180\n",
      "F1 Macro Score: 0.93822\n",
      " - 12s - loss: 0.0849 - acc: 0.9700 - val_loss: 0.0814 - val_acc: 0.9705\n",
      "Epoch 34/180\n",
      "F1 Macro Score: 0.93832\n",
      " - 12s - loss: 0.0854 - acc: 0.9699 - val_loss: 0.0815 - val_acc: 0.9705\n",
      "Epoch 35/180\n",
      "F1 Macro Score: 0.93905\n",
      " - 12s - loss: 0.0849 - acc: 0.9700 - val_loss: 0.0802 - val_acc: 0.9708\n",
      "Epoch 36/180\n",
      "F1 Macro Score: 0.93846\n",
      " - 12s - loss: 0.0847 - acc: 0.9700 - val_loss: 0.0814 - val_acc: 0.9705\n",
      "Epoch 37/180\n",
      "F1 Macro Score: 0.93876\n",
      " - 12s - loss: 0.0848 - acc: 0.9700 - val_loss: 0.0804 - val_acc: 0.9708\n",
      "Epoch 38/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0844 - acc: 0.9700 - val_loss: 0.0801 - val_acc: 0.9708\n",
      "Epoch 39/180\n",
      "F1 Macro Score: 0.93868\n",
      " - 12s - loss: 0.0844 - acc: 0.9700 - val_loss: 0.0809 - val_acc: 0.9706\n",
      "Epoch 40/180\n",
      "F1 Macro Score: 0.93883\n",
      " - 12s - loss: 0.0850 - acc: 0.9698 - val_loss: 0.0811 - val_acc: 0.9705\n",
      "Epoch 41/180\n",
      "F1 Macro Score: 0.93924\n",
      " - 12s - loss: 0.0838 - acc: 0.9700 - val_loss: 0.0796 - val_acc: 0.9709\n",
      "Epoch 42/180\n",
      "F1 Macro Score: 0.93839\n",
      " - 12s - loss: 0.0831 - acc: 0.9701 - val_loss: 0.0805 - val_acc: 0.9707\n",
      "Epoch 43/180\n",
      "F1 Macro Score: 0.93947\n",
      " - 12s - loss: 0.0831 - acc: 0.9701 - val_loss: 0.0794 - val_acc: 0.9710\n",
      "Epoch 44/180\n",
      "F1 Macro Score: 0.93904\n",
      " - 12s - loss: 0.0832 - acc: 0.9701 - val_loss: 0.0797 - val_acc: 0.9708\n",
      "Epoch 45/180\n",
      "F1 Macro Score: 0.93933\n",
      " - 12s - loss: 0.0833 - acc: 0.9701 - val_loss: 0.0792 - val_acc: 0.9709\n",
      "Epoch 46/180\n",
      "F1 Macro Score: 0.93861\n",
      " - 12s - loss: 0.0829 - acc: 0.9701 - val_loss: 0.0799 - val_acc: 0.9706\n",
      "Epoch 47/180\n",
      "F1 Macro Score: 0.93898\n",
      " - 12s - loss: 0.0836 - acc: 0.9700 - val_loss: 0.0800 - val_acc: 0.9708\n",
      "Epoch 48/180\n",
      "F1 Macro Score: 0.93906\n",
      " - 12s - loss: 0.0830 - acc: 0.9701 - val_loss: 0.0794 - val_acc: 0.9708\n",
      "Epoch 49/180\n",
      "F1 Macro Score: 0.93891\n",
      " - 12s - loss: 0.0828 - acc: 0.9701 - val_loss: 0.0796 - val_acc: 0.9707\n",
      "Epoch 50/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.0824 - acc: 0.9702 - val_loss: 0.0790 - val_acc: 0.9709\n",
      "Epoch 51/180\n",
      "F1 Macro Score: 0.93863\n",
      " - 12s - loss: 0.0824 - acc: 0.9702 - val_loss: 0.0800 - val_acc: 0.9705\n",
      "Epoch 52/180\n",
      "F1 Macro Score: 0.93910\n",
      " - 12s - loss: 0.0825 - acc: 0.9702 - val_loss: 0.0794 - val_acc: 0.9707\n",
      "Epoch 53/180\n",
      "F1 Macro Score: 0.93941\n",
      " - 12s - loss: 0.0819 - acc: 0.9702 - val_loss: 0.0792 - val_acc: 0.9709\n",
      "Epoch 54/180\n",
      "F1 Macro Score: 0.93837\n",
      " - 12s - loss: 0.0828 - acc: 0.9701 - val_loss: 0.0803 - val_acc: 0.9704\n",
      "Epoch 55/180\n",
      "F1 Macro Score: 0.93909\n",
      " - 12s - loss: 0.0835 - acc: 0.9701 - val_loss: 0.0793 - val_acc: 0.9708\n",
      "Epoch 56/180\n",
      "F1 Macro Score: 0.93780\n",
      " - 12s - loss: 0.0828 - acc: 0.9701 - val_loss: 0.0807 - val_acc: 0.9703\n",
      "Epoch 57/180\n",
      "F1 Macro Score: 0.93758\n",
      " - 12s - loss: 0.0816 - acc: 0.9703 - val_loss: 0.0804 - val_acc: 0.9705\n",
      "Epoch 58/180\n",
      "F1 Macro Score: 0.93942\n",
      " - 12s - loss: 0.0820 - acc: 0.9702 - val_loss: 0.0788 - val_acc: 0.9709\n",
      "Epoch 59/180\n",
      "F1 Macro Score: 0.93857\n",
      " - 12s - loss: 0.0818 - acc: 0.9703 - val_loss: 0.0794 - val_acc: 0.9707\n",
      "Epoch 60/180\n",
      "F1 Macro Score: 0.93894\n",
      " - 12s - loss: 0.0815 - acc: 0.9703 - val_loss: 0.0793 - val_acc: 0.9707\n",
      "Epoch 61/180\n",
      "F1 Macro Score: 0.93866\n",
      " - 12s - loss: 0.0811 - acc: 0.9703 - val_loss: 0.0794 - val_acc: 0.9705\n",
      "Epoch 62/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0812 - acc: 0.9704 - val_loss: 0.0788 - val_acc: 0.9708\n",
      "Epoch 63/180\n",
      "F1 Macro Score: 0.93866\n",
      " - 12s - loss: 0.0815 - acc: 0.9704 - val_loss: 0.0795 - val_acc: 0.9705\n",
      "Epoch 64/180\n",
      "F1 Macro Score: 0.93884\n",
      " - 12s - loss: 0.0810 - acc: 0.9704 - val_loss: 0.0791 - val_acc: 0.9706\n",
      "Epoch 65/180\n",
      "F1 Macro Score: 0.93919\n",
      " - 12s - loss: 0.0817 - acc: 0.9703 - val_loss: 0.0789 - val_acc: 0.9708\n",
      "Epoch 66/180\n",
      "F1 Macro Score: 0.93924\n",
      " - 12s - loss: 0.0807 - acc: 0.9704 - val_loss: 0.0788 - val_acc: 0.9708\n",
      "Epoch 67/180\n",
      "F1 Macro Score: 0.93942\n",
      " - 12s - loss: 0.0807 - acc: 0.9704 - val_loss: 0.0785 - val_acc: 0.9709\n",
      "Epoch 68/180\n",
      "F1 Macro Score: 0.93812\n",
      " - 12s - loss: 0.0812 - acc: 0.9702 - val_loss: 0.0807 - val_acc: 0.9702\n",
      "Epoch 69/180\n",
      "F1 Macro Score: 0.93819\n",
      " - 12s - loss: 0.0816 - acc: 0.9702 - val_loss: 0.0800 - val_acc: 0.9704\n",
      "Epoch 70/180\n",
      "F1 Macro Score: 0.93737\n",
      " - 12s - loss: 0.0819 - acc: 0.9702 - val_loss: 0.0804 - val_acc: 0.9703\n",
      "Epoch 71/180\n",
      "F1 Macro Score: 0.93896\n",
      " - 12s - loss: 0.0813 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9707\n",
      "Epoch 72/180\n",
      "F1 Macro Score: 0.93947\n",
      " - 12s - loss: 0.0815 - acc: 0.9703 - val_loss: 0.0785 - val_acc: 0.9709\n",
      "Epoch 73/180\n",
      "F1 Macro Score: 0.93875\n",
      " - 12s - loss: 0.0807 - acc: 0.9705 - val_loss: 0.0791 - val_acc: 0.9706\n",
      "Epoch 74/180\n",
      "F1 Macro Score: 0.93925\n",
      " - 12s - loss: 0.0803 - acc: 0.9705 - val_loss: 0.0787 - val_acc: 0.9708\n",
      "Epoch 75/180\n",
      "F1 Macro Score: 0.93928\n",
      " - 12s - loss: 0.0803 - acc: 0.9705 - val_loss: 0.0785 - val_acc: 0.9708\n",
      "Epoch 76/180\n",
      "F1 Macro Score: 0.93893\n",
      " - 12s - loss: 0.0797 - acc: 0.9706 - val_loss: 0.0789 - val_acc: 0.9706\n",
      "Epoch 77/180\n",
      "F1 Macro Score: 0.93870\n",
      " - 12s - loss: 0.0801 - acc: 0.9706 - val_loss: 0.0790 - val_acc: 0.9706\n",
      "Epoch 78/180\n",
      "F1 Macro Score: 0.93865\n",
      " - 12s - loss: 0.0800 - acc: 0.9705 - val_loss: 0.0791 - val_acc: 0.9705\n",
      "Epoch 79/180\n",
      "F1 Macro Score: 0.93887\n",
      " - 12s - loss: 0.0800 - acc: 0.9705 - val_loss: 0.0792 - val_acc: 0.9706\n",
      "Epoch 80/180\n",
      "F1 Macro Score: 0.93913\n",
      " - 12s - loss: 0.0796 - acc: 0.9706 - val_loss: 0.0786 - val_acc: 0.9707\n",
      "Epoch 81/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0797 - acc: 0.9706 - val_loss: 0.0784 - val_acc: 0.9708\n",
      "Epoch 82/180\n",
      "F1 Macro Score: 0.93888\n",
      " - 12s - loss: 0.0800 - acc: 0.9705 - val_loss: 0.0785 - val_acc: 0.9706\n",
      "Epoch 83/180\n",
      "F1 Macro Score: 0.93868\n",
      " - 12s - loss: 0.0795 - acc: 0.9707 - val_loss: 0.0791 - val_acc: 0.9705\n",
      "Epoch 84/180\n",
      "F1 Macro Score: 0.93910\n",
      " - 12s - loss: 0.0791 - acc: 0.9706 - val_loss: 0.0783 - val_acc: 0.9707\n",
      "Epoch 85/180\n",
      "F1 Macro Score: 0.93871\n",
      " - 12s - loss: 0.0793 - acc: 0.9707 - val_loss: 0.0787 - val_acc: 0.9706\n",
      "Epoch 86/180\n",
      "F1 Macro Score: 0.93920\n",
      " - 12s - loss: 0.0798 - acc: 0.9706 - val_loss: 0.0785 - val_acc: 0.9707\n",
      "Epoch 87/180\n",
      "F1 Macro Score: 0.93860\n",
      " - 12s - loss: 0.0801 - acc: 0.9705 - val_loss: 0.0792 - val_acc: 0.9705\n",
      "Epoch 88/180\n",
      "F1 Macro Score: 0.93906\n",
      " - 12s - loss: 0.0802 - acc: 0.9704 - val_loss: 0.0788 - val_acc: 0.9706\n",
      "Epoch 89/180\n",
      "F1 Macro Score: 0.93908\n",
      " - 12s - loss: 0.0796 - acc: 0.9706 - val_loss: 0.0786 - val_acc: 0.9707\n",
      "Epoch 90/180\n",
      "F1 Macro Score: 0.93900\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0786 - val_acc: 0.9706\n",
      "Epoch 91/180\n",
      "F1 Macro Score: 0.93882\n",
      " - 12s - loss: 0.0789 - acc: 0.9707 - val_loss: 0.0785 - val_acc: 0.9707\n",
      "Epoch 92/180\n",
      "F1 Macro Score: 0.93918\n",
      " - 12s - loss: 0.0789 - acc: 0.9707 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 93/180\n",
      "F1 Macro Score: 0.93920\n",
      " - 12s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 94/180\n",
      "F1 Macro Score: 0.93911\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 95/180\n",
      "F1 Macro Score: 0.93927\n",
      " - 12s - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 96/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0785 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9708\n",
      "Epoch 97/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0785 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9708\n",
      "Epoch 98/180\n",
      "F1 Macro Score: 0.93921\n",
      " - 12s - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 99/180\n",
      "F1 Macro Score: 0.93915\n",
      " - 12s - loss: 0.0785 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 100/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.0786 - acc: 0.9708 - val_loss: 0.0781 - val_acc: 0.9708\n",
      "Epoch 101/180\n",
      "F1 Macro Score: 0.93939\n",
      " - 12s - loss: 0.0784 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 102/180\n",
      "F1 Macro Score: 0.93914\n",
      " - 12s - loss: 0.0787 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 103/180\n",
      "F1 Macro Score: 0.93915\n",
      " - 12s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 104/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0781 - val_acc: 0.9708\n",
      "Epoch 105/180\n",
      "F1 Macro Score: 0.93911\n",
      " - 12s - loss: 0.0784 - acc: 0.9708 - val_loss: 0.0782 - val_acc: 0.9708\n",
      "Epoch 106/180\n",
      "F1 Macro Score: 0.93908\n",
      " - 12s - loss: 0.0781 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 107/180\n",
      "F1 Macro Score: 0.93938\n",
      " - 12s - loss: 0.0782 - acc: 0.9708 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 108/180\n",
      "F1 Macro Score: 0.93925\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 109/180\n",
      "F1 Macro Score: 0.93930\n",
      " - 12s - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9708\n",
      "Epoch 110/180\n",
      "F1 Macro Score: 0.93928\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 111/180\n",
      "F1 Macro Score: 0.93921\n",
      " - 12s - loss: 0.0782 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 112/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 113/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.0781 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 114/180\n",
      "F1 Macro Score: 0.93925\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 115/180\n",
      "F1 Macro Score: 0.93925\n",
      " - 12s - loss: 0.0787 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 116/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0781 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 117/180\n",
      "F1 Macro Score: 0.93907\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 118/180\n",
      "F1 Macro Score: 0.93904\n",
      " - 12s - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0783 - val_acc: 0.9707\n",
      "Epoch 119/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.0782 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 120/180\n",
      "F1 Macro Score: 0.93918\n",
      " - 12s - loss: 0.0779 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 121/180\n",
      "F1 Macro Score: 0.93923\n",
      " - 12s - loss: 0.0784 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 122/180\n",
      "F1 Macro Score: 0.93913\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 123/180\n",
      "F1 Macro Score: 0.93919\n",
      " - 12s - loss: 0.0787 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 124/180\n",
      "F1 Macro Score: 0.93899\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 125/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9708\n",
      "Epoch 126/180\n",
      "F1 Macro Score: 0.93913\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 127/180\n",
      "F1 Macro Score: 0.93919\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9708\n",
      "Epoch 128/180\n",
      "F1 Macro Score: 0.93896\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0783 - val_acc: 0.9707\n",
      "Epoch 129/180\n",
      "F1 Macro Score: 0.93910\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 130/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 131/180\n",
      "F1 Macro Score: 0.93916\n",
      " - 12s - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 132/180\n",
      "F1 Macro Score: 0.93887\n",
      " - 12s - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0784 - val_acc: 0.9706\n",
      "Epoch 133/180\n",
      "F1 Macro Score: 0.93924\n",
      " - 12s - loss: 0.0779 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 134/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 135/180\n",
      "F1 Macro Score: 0.93903\n",
      " - 12s - loss: 0.0779 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 136/180\n",
      "F1 Macro Score: 0.93915\n",
      " - 12s - loss: 0.0779 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 137/180\n",
      "F1 Macro Score: 0.93914\n",
      " - 12s - loss: 0.0780 - acc: 0.9708 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 138/180\n",
      "F1 Macro Score: 0.93924\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 139/180\n",
      "F1 Macro Score: 0.93918\n",
      " - 12s - loss: 0.0775 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 140/180\n",
      "F1 Macro Score: 0.93912\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 141/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.0781 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9708\n",
      "Epoch 142/180\n",
      "F1 Macro Score: 0.93920\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 143/180\n",
      "F1 Macro Score: 0.93905\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 144/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 145/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0777 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 146/180\n",
      "F1 Macro Score: 0.93886\n",
      " - 12s - loss: 0.0777 - acc: 0.9709 - val_loss: 0.0782 - val_acc: 0.9706\n",
      "Epoch 147/180\n",
      "F1 Macro Score: 0.93925\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 148/180\n",
      "F1 Macro Score: 0.93924\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 149/180\n",
      "F1 Macro Score: 0.93899\n",
      " - 12s - loss: 0.0782 - acc: 0.9708 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 150/180\n",
      "F1 Macro Score: 0.93885\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0784 - val_acc: 0.9706\n",
      "Epoch 151/180\n",
      "F1 Macro Score: 0.93910\n",
      " - 12s - loss: 0.0779 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 152/180\n",
      "F1 Macro Score: 0.93879\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0784 - val_acc: 0.9706\n",
      "Epoch 153/180\n",
      "F1 Macro Score: 0.93905\n",
      " - 12s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 154/180\n",
      "F1 Macro Score: 0.93916\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 155/180\n",
      "F1 Macro Score: 0.93906\n",
      " - 12s - loss: 0.0775 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 156/180\n",
      "F1 Macro Score: 0.93911\n",
      " - 12s - loss: 0.0775 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 157/180\n",
      "F1 Macro Score: 0.93901\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 158/180\n",
      "F1 Macro Score: 0.93909\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 159/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 160/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 161/180\n",
      "F1 Macro Score: 0.93908\n",
      " - 12s - loss: 0.0775 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9706\n",
      "Epoch 162/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0779 - acc: 0.9709 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 163/180\n",
      "F1 Macro Score: 0.93918\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 164/180\n",
      "F1 Macro Score: 0.93923\n",
      " - 12s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 165/180\n",
      "F1 Macro Score: 0.93923\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 166/180\n",
      "F1 Macro Score: 0.93905\n",
      " - 12s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 167/180\n",
      "F1 Macro Score: 0.93909\n",
      " - 12s - loss: 0.0773 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 168/180\n",
      "F1 Macro Score: 0.93906\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9707\n",
      "Epoch 169/180\n",
      "F1 Macro Score: 0.93928\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 170/180\n",
      "F1 Macro Score: 0.93934\n",
      " - 12s - loss: 0.0775 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 171/180\n",
      "F1 Macro Score: 0.93912\n",
      " - 12s - loss: 0.0774 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 172/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 173/180\n",
      "F1 Macro Score: 0.93902\n",
      " - 12s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9706\n",
      "Epoch 174/180\n",
      "F1 Macro Score: 0.93913\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0779 - val_acc: 0.9707\n",
      "Epoch 175/180\n",
      "F1 Macro Score: 0.93918\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0778 - val_acc: 0.9707\n",
      "Epoch 176/180\n",
      "F1 Macro Score: 0.93914\n",
      " - 12s - loss: 0.0774 - acc: 0.9710 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 177/180\n",
      "F1 Macro Score: 0.93927\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Epoch 178/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.0777 - acc: 0.9709 - val_loss: 0.0778 - val_acc: 0.9708\n",
      "Epoch 179/180\n",
      "F1 Macro Score: 0.93906\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0780 - val_acc: 0.9707\n",
      "Epoch 180/180\n",
      "F1 Macro Score: 0.93927\n",
      " - 12s - loss: 0.0773 - acc: 0.9710 - val_loss: 0.0779 - val_acc: 0.9708\n",
      "Training fold 3 completed. macro f1 score : 0.93927\n",
      "Our training dataset shape is (1000, 4000, 23)\n",
      "Our validation dataset shape is (250, 4000, 23)\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/180\n",
      "F1 Macro Score: 0.75048\n",
      " - 21s - loss: 0.4674 - acc: 0.8659 - val_loss: 0.7685 - val_acc: 0.9142\n",
      "Epoch 2/180\n",
      "F1 Macro Score: 0.89838\n",
      " - 12s - loss: 0.1527 - acc: 0.9638 - val_loss: 0.3640 - val_acc: 0.9580\n",
      "Epoch 3/180\n",
      "F1 Macro Score: 0.93079\n",
      " - 12s - loss: 0.1280 - acc: 0.9675 - val_loss: 0.1893 - val_acc: 0.9666\n",
      "Epoch 4/180\n",
      "F1 Macro Score: 0.93712\n",
      " - 12s - loss: 0.1173 - acc: 0.9683 - val_loss: 0.1332 - val_acc: 0.9689\n",
      "Epoch 5/180\n",
      "F1 Macro Score: 0.92940\n",
      " - 12s - loss: 0.1162 - acc: 0.9682 - val_loss: 0.1254 - val_acc: 0.9666\n",
      "Epoch 6/180\n",
      "F1 Macro Score: 0.93878\n",
      " - 12s - loss: 0.1196 - acc: 0.9679 - val_loss: 0.0991 - val_acc: 0.9699\n",
      "Epoch 7/180\n",
      "F1 Macro Score: 0.93960\n",
      " - 12s - loss: 0.1102 - acc: 0.9688 - val_loss: 0.0970 - val_acc: 0.9699\n",
      "Epoch 8/180\n",
      "F1 Macro Score: 0.94014\n",
      " - 12s - loss: 0.1050 - acc: 0.9692 - val_loss: 0.0912 - val_acc: 0.9703\n",
      "Epoch 9/180\n",
      "F1 Macro Score: 0.93907\n",
      " - 12s - loss: 0.1024 - acc: 0.9693 - val_loss: 0.0934 - val_acc: 0.9698\n",
      "Epoch 10/180\n",
      "F1 Macro Score: 0.93957\n",
      " - 12s - loss: 0.1006 - acc: 0.9695 - val_loss: 0.0899 - val_acc: 0.9702\n",
      "Epoch 11/180\n",
      "F1 Macro Score: 0.93992\n",
      " - 12s - loss: 0.0986 - acc: 0.9695 - val_loss: 0.0914 - val_acc: 0.9702\n",
      "Epoch 12/180\n",
      "F1 Macro Score: 0.93994\n",
      " - 12s - loss: 0.1018 - acc: 0.9692 - val_loss: 0.0888 - val_acc: 0.9703\n",
      "Epoch 13/180\n",
      "F1 Macro Score: 0.94026\n",
      " - 12s - loss: 0.1066 - acc: 0.9686 - val_loss: 0.0906 - val_acc: 0.9704\n",
      "Epoch 14/180\n",
      "F1 Macro Score: 0.93566\n",
      " - 12s - loss: 0.1012 - acc: 0.9693 - val_loss: 0.1024 - val_acc: 0.9681\n",
      "Epoch 15/180\n",
      "F1 Macro Score: 0.93963\n",
      " - 12s - loss: 0.0971 - acc: 0.9695 - val_loss: 0.0886 - val_acc: 0.9701\n",
      "Epoch 16/180\n",
      "F1 Macro Score: 0.94027\n",
      " - 12s - loss: 0.0942 - acc: 0.9696 - val_loss: 0.0868 - val_acc: 0.9703\n",
      "Epoch 17/180\n",
      "F1 Macro Score: 0.93975\n",
      " - 12s - loss: 0.0952 - acc: 0.9695 - val_loss: 0.0876 - val_acc: 0.9701\n",
      "Epoch 18/180\n",
      "F1 Macro Score: 0.93950\n",
      " - 12s - loss: 0.0940 - acc: 0.9696 - val_loss: 0.0874 - val_acc: 0.9700\n",
      "Epoch 19/180\n",
      "F1 Macro Score: 0.93984\n",
      " - 12s - loss: 0.0926 - acc: 0.9696 - val_loss: 0.0866 - val_acc: 0.9701\n",
      "Epoch 20/180\n",
      "F1 Macro Score: 0.93964\n",
      " - 12s - loss: 0.0918 - acc: 0.9696 - val_loss: 0.0877 - val_acc: 0.9701\n",
      "Epoch 21/180\n",
      "F1 Macro Score: 0.93845\n",
      " - 12s - loss: 0.0918 - acc: 0.9695 - val_loss: 0.0886 - val_acc: 0.9694\n",
      "Epoch 22/180\n",
      "F1 Macro Score: 0.94065\n",
      " - 12s - loss: 0.0916 - acc: 0.9696 - val_loss: 0.0829 - val_acc: 0.9706\n",
      "Epoch 23/180\n",
      "F1 Macro Score: 0.94013\n",
      " - 12s - loss: 0.0889 - acc: 0.9697 - val_loss: 0.0831 - val_acc: 0.9703\n",
      "Epoch 24/180\n",
      "F1 Macro Score: 0.93963\n",
      " - 12s - loss: 0.0896 - acc: 0.9696 - val_loss: 0.0856 - val_acc: 0.9700\n",
      "Epoch 25/180\n",
      "F1 Macro Score: 0.93565\n",
      " - 12s - loss: 0.0900 - acc: 0.9695 - val_loss: 0.0942 - val_acc: 0.9685\n",
      "Epoch 26/180\n",
      "F1 Macro Score: 0.93781\n",
      " - 12s - loss: 0.0885 - acc: 0.9697 - val_loss: 0.0847 - val_acc: 0.9700\n",
      "Epoch 27/180\n",
      "F1 Macro Score: 0.94064\n",
      " - 12s - loss: 0.0884 - acc: 0.9698 - val_loss: 0.0821 - val_acc: 0.9705\n",
      "Epoch 28/180\n",
      "F1 Macro Score: 0.93798\n",
      " - 12s - loss: 0.0880 - acc: 0.9697 - val_loss: 0.0866 - val_acc: 0.9695\n",
      "Epoch 29/180\n",
      "F1 Macro Score: 0.94004\n",
      " - 12s - loss: 0.0885 - acc: 0.9696 - val_loss: 0.0828 - val_acc: 0.9702\n",
      "Epoch 30/180\n",
      "F1 Macro Score: 0.93998\n",
      " - 12s - loss: 0.0877 - acc: 0.9697 - val_loss: 0.0837 - val_acc: 0.9702\n",
      "Epoch 31/180\n",
      "F1 Macro Score: 0.94038\n",
      " - 12s - loss: 0.0857 - acc: 0.9700 - val_loss: 0.0813 - val_acc: 0.9704\n",
      "Epoch 32/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0857 - acc: 0.9699 - val_loss: 0.0815 - val_acc: 0.9704\n",
      "Epoch 33/180\n",
      "F1 Macro Score: 0.94062\n",
      " - 12s - loss: 0.0842 - acc: 0.9700 - val_loss: 0.0808 - val_acc: 0.9705\n",
      "Epoch 34/180\n",
      "F1 Macro Score: 0.94028\n",
      " - 12s - loss: 0.0843 - acc: 0.9700 - val_loss: 0.0805 - val_acc: 0.9704\n",
      "Epoch 35/180\n",
      "F1 Macro Score: 0.94085\n",
      " - 12s - loss: 0.0837 - acc: 0.9701 - val_loss: 0.0806 - val_acc: 0.9705\n",
      "Epoch 36/180\n",
      "F1 Macro Score: 0.94043\n",
      " - 12s - loss: 0.0835 - acc: 0.9701 - val_loss: 0.0807 - val_acc: 0.9703\n",
      "Epoch 37/180\n",
      "F1 Macro Score: 0.94015\n",
      " - 12s - loss: 0.0840 - acc: 0.9700 - val_loss: 0.0806 - val_acc: 0.9704\n",
      "Epoch 38/180\n",
      "F1 Macro Score: 0.94052\n",
      " - 12s - loss: 0.0843 - acc: 0.9699 - val_loss: 0.0803 - val_acc: 0.9704\n",
      "Epoch 39/180\n",
      "F1 Macro Score: 0.94056\n",
      " - 12s - loss: 0.0858 - acc: 0.9698 - val_loss: 0.0807 - val_acc: 0.9704\n",
      "Epoch 40/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0841 - acc: 0.9701 - val_loss: 0.0801 - val_acc: 0.9705\n",
      "Epoch 41/180\n",
      "F1 Macro Score: 0.94024\n",
      " - 12s - loss: 0.0832 - acc: 0.9701 - val_loss: 0.0804 - val_acc: 0.9703\n",
      "Epoch 42/180\n",
      "F1 Macro Score: 0.94005\n",
      " - 12s - loss: 0.0822 - acc: 0.9703 - val_loss: 0.0801 - val_acc: 0.9703\n",
      "Epoch 43/180\n",
      "F1 Macro Score: 0.94013\n",
      " - 12s - loss: 0.0829 - acc: 0.9702 - val_loss: 0.0802 - val_acc: 0.9703\n",
      "Epoch 44/180\n",
      "F1 Macro Score: 0.94041\n",
      " - 12s - loss: 0.0825 - acc: 0.9702 - val_loss: 0.0802 - val_acc: 0.9703\n",
      "Epoch 45/180\n",
      "F1 Macro Score: 0.94011\n",
      " - 12s - loss: 0.0821 - acc: 0.9702 - val_loss: 0.0799 - val_acc: 0.9704\n",
      "Epoch 46/180\n",
      "F1 Macro Score: 0.94034\n",
      " - 12s - loss: 0.0820 - acc: 0.9702 - val_loss: 0.0801 - val_acc: 0.9703\n",
      "Epoch 47/180\n",
      "F1 Macro Score: 0.94045\n",
      " - 12s - loss: 0.0818 - acc: 0.9703 - val_loss: 0.0795 - val_acc: 0.9704\n",
      "Epoch 48/180\n",
      "F1 Macro Score: 0.94046\n",
      " - 12s - loss: 0.0820 - acc: 0.9702 - val_loss: 0.0794 - val_acc: 0.9705\n",
      "Epoch 49/180\n",
      "F1 Macro Score: 0.94034\n",
      " - 12s - loss: 0.0818 - acc: 0.9704 - val_loss: 0.0802 - val_acc: 0.9703\n",
      "Epoch 50/180\n",
      "F1 Macro Score: 0.94065\n",
      " - 12s - loss: 0.0813 - acc: 0.9704 - val_loss: 0.0791 - val_acc: 0.9704\n",
      "Epoch 51/180\n",
      "F1 Macro Score: 0.94054\n",
      " - 12s - loss: 0.0814 - acc: 0.9704 - val_loss: 0.0794 - val_acc: 0.9704\n",
      "Epoch 52/180\n",
      "F1 Macro Score: 0.94062\n",
      " - 12s - loss: 0.0811 - acc: 0.9704 - val_loss: 0.0792 - val_acc: 0.9704\n",
      "Epoch 53/180\n",
      "F1 Macro Score: 0.94028\n",
      " - 12s - loss: 0.0811 - acc: 0.9704 - val_loss: 0.0798 - val_acc: 0.9702\n",
      "Epoch 54/180\n",
      "F1 Macro Score: 0.93977\n",
      " - 12s - loss: 0.0807 - acc: 0.9704 - val_loss: 0.0800 - val_acc: 0.9702\n",
      "Epoch 55/180\n",
      "F1 Macro Score: 0.94076\n",
      " - 12s - loss: 0.0810 - acc: 0.9704 - val_loss: 0.0790 - val_acc: 0.9705\n",
      "Epoch 56/180\n",
      "F1 Macro Score: 0.94055\n",
      " - 12s - loss: 0.0810 - acc: 0.9704 - val_loss: 0.0793 - val_acc: 0.9704\n",
      "Epoch 57/180\n",
      "F1 Macro Score: 0.93978\n",
      " - 12s - loss: 0.0809 - acc: 0.9704 - val_loss: 0.0794 - val_acc: 0.9703\n",
      "Epoch 58/180\n",
      "F1 Macro Score: 0.94066\n",
      " - 12s - loss: 0.0808 - acc: 0.9703 - val_loss: 0.0792 - val_acc: 0.9704\n",
      "Epoch 59/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0806 - acc: 0.9704 - val_loss: 0.0817 - val_acc: 0.9697\n",
      "Epoch 60/180\n",
      "F1 Macro Score: 0.94061\n",
      " - 12s - loss: 0.0806 - acc: 0.9704 - val_loss: 0.0792 - val_acc: 0.9704\n",
      "Epoch 61/180\n",
      "F1 Macro Score: 0.94056\n",
      " - 12s - loss: 0.0812 - acc: 0.9704 - val_loss: 0.0789 - val_acc: 0.9704\n",
      "Epoch 62/180\n",
      "F1 Macro Score: 0.94024\n",
      " - 12s - loss: 0.0802 - acc: 0.9705 - val_loss: 0.0791 - val_acc: 0.9704\n",
      "Epoch 63/180\n",
      "F1 Macro Score: 0.94007\n",
      " - 12s - loss: 0.0804 - acc: 0.9705 - val_loss: 0.0802 - val_acc: 0.9701\n",
      "Epoch 64/180\n",
      "F1 Macro Score: 0.94031\n",
      " - 12s - loss: 0.0799 - acc: 0.9706 - val_loss: 0.0790 - val_acc: 0.9704\n",
      "Epoch 65/180\n",
      "F1 Macro Score: 0.94058\n",
      " - 12s - loss: 0.0800 - acc: 0.9705 - val_loss: 0.0787 - val_acc: 0.9704\n",
      "Epoch 66/180\n",
      "F1 Macro Score: 0.94064\n",
      " - 12s - loss: 0.0796 - acc: 0.9706 - val_loss: 0.0791 - val_acc: 0.9704\n",
      "Epoch 67/180\n",
      "F1 Macro Score: 0.94039\n",
      " - 12s - loss: 0.0796 - acc: 0.9706 - val_loss: 0.0789 - val_acc: 0.9704\n",
      "Epoch 68/180\n",
      "F1 Macro Score: 0.94060\n",
      " - 12s - loss: 0.0798 - acc: 0.9705 - val_loss: 0.0788 - val_acc: 0.9704\n",
      "Epoch 69/180\n",
      "F1 Macro Score: 0.93985\n",
      " - 12s - loss: 0.0798 - acc: 0.9706 - val_loss: 0.0803 - val_acc: 0.9701\n",
      "Epoch 70/180\n",
      "F1 Macro Score: 0.94031\n",
      " - 12s - loss: 0.0799 - acc: 0.9706 - val_loss: 0.0791 - val_acc: 0.9702\n",
      "Epoch 71/180\n",
      "F1 Macro Score: 0.94069\n",
      " - 12s - loss: 0.0798 - acc: 0.9705 - val_loss: 0.0788 - val_acc: 0.9704\n",
      "Epoch 72/180\n",
      "F1 Macro Score: 0.94036\n",
      " - 12s - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0790 - val_acc: 0.9703\n",
      "Epoch 73/180\n",
      "F1 Macro Score: 0.93973\n",
      " - 12s - loss: 0.0793 - acc: 0.9707 - val_loss: 0.0793 - val_acc: 0.9702\n",
      "Epoch 74/180\n",
      "F1 Macro Score: 0.94058\n",
      " - 12s - loss: 0.0794 - acc: 0.9706 - val_loss: 0.0787 - val_acc: 0.9704\n",
      "Epoch 75/180\n",
      "F1 Macro Score: 0.94058\n",
      " - 12s - loss: 0.0793 - acc: 0.9707 - val_loss: 0.0788 - val_acc: 0.9704\n",
      "Epoch 76/180\n",
      "F1 Macro Score: 0.94046\n",
      " - 12s - loss: 0.0789 - acc: 0.9708 - val_loss: 0.0788 - val_acc: 0.9704\n",
      "Epoch 77/180\n",
      "F1 Macro Score: 0.94057\n",
      " - 12s - loss: 0.0789 - acc: 0.9708 - val_loss: 0.0789 - val_acc: 0.9704\n",
      "Epoch 78/180\n",
      "F1 Macro Score: 0.93913\n",
      " - 12s - loss: 0.0799 - acc: 0.9706 - val_loss: 0.0813 - val_acc: 0.9697\n",
      "Epoch 79/180\n",
      "F1 Macro Score: 0.94056\n",
      " - 12s - loss: 0.0787 - acc: 0.9709 - val_loss: 0.0790 - val_acc: 0.9704\n",
      "Epoch 80/180\n",
      "F1 Macro Score: 0.94030\n",
      " - 12s - loss: 0.0791 - acc: 0.9707 - val_loss: 0.0790 - val_acc: 0.9703\n",
      "Epoch 81/180\n",
      "F1 Macro Score: 0.94032\n",
      " - 12s - loss: 0.0786 - acc: 0.9708 - val_loss: 0.0789 - val_acc: 0.9703\n",
      "Epoch 82/180\n",
      "F1 Macro Score: 0.94049\n",
      " - 12s - loss: 0.0786 - acc: 0.9708 - val_loss: 0.0786 - val_acc: 0.9704\n",
      "Epoch 83/180\n",
      "F1 Macro Score: 0.94044\n",
      " - 12s - loss: 0.0786 - acc: 0.9708 - val_loss: 0.0787 - val_acc: 0.9703\n",
      "Epoch 84/180\n",
      "F1 Macro Score: 0.94020\n",
      " - 12s - loss: 0.0788 - acc: 0.9708 - val_loss: 0.0794 - val_acc: 0.9701\n",
      "Epoch 85/180\n",
      "F1 Macro Score: 0.94014\n",
      " - 12s - loss: 0.0782 - acc: 0.9710 - val_loss: 0.0791 - val_acc: 0.9702\n",
      "Epoch 86/180\n",
      "F1 Macro Score: 0.94030\n",
      " - 12s - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0790 - val_acc: 0.9702\n",
      "Epoch 87/180\n",
      "F1 Macro Score: 0.94013\n",
      " - 12s - loss: 0.0781 - acc: 0.9710 - val_loss: 0.0789 - val_acc: 0.9703\n",
      "Epoch 88/180\n",
      "F1 Macro Score: 0.94021\n",
      " - 12s - loss: 0.0781 - acc: 0.9709 - val_loss: 0.0790 - val_acc: 0.9702\n",
      "Epoch 89/180\n",
      "F1 Macro Score: 0.94055\n",
      " - 12s - loss: 0.0789 - acc: 0.9708 - val_loss: 0.0792 - val_acc: 0.9703\n",
      "Epoch 90/180\n",
      "F1 Macro Score: 0.94051\n",
      " - 12s - loss: 0.0780 - acc: 0.9710 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 91/180\n",
      "F1 Macro Score: 0.94067\n",
      " - 12s - loss: 0.0776 - acc: 0.9710 - val_loss: 0.0786 - val_acc: 0.9704\n",
      "Epoch 92/180\n",
      "F1 Macro Score: 0.94054\n",
      " - 12s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 93/180\n",
      "F1 Macro Score: 0.94059\n",
      " - 12s - loss: 0.0776 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 94/180\n",
      "F1 Macro Score: 0.94057\n",
      " - 12s - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 95/180\n",
      "F1 Macro Score: 0.94053\n",
      " - 12s - loss: 0.0776 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 96/180\n",
      "F1 Macro Score: 0.94055\n",
      " - 12s - loss: 0.0771 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 97/180\n",
      "F1 Macro Score: 0.94064\n",
      " - 12s - loss: 0.0772 - acc: 0.9712 - val_loss: 0.0784 - val_acc: 0.9704\n",
      "Epoch 98/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0778 - acc: 0.9710 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 99/180\n",
      "F1 Macro Score: 0.94058\n",
      " - 12s - loss: 0.0775 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 100/180\n",
      "F1 Macro Score: 0.94049\n",
      " - 12s - loss: 0.0775 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 101/180\n",
      "F1 Macro Score: 0.94057\n",
      " - 12s - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 102/180\n",
      "F1 Macro Score: 0.94057\n",
      " - 12s - loss: 0.0772 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9704\n",
      "Epoch 103/180\n",
      "F1 Macro Score: 0.94064\n",
      " - 12s - loss: 0.0773 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 104/180\n",
      "F1 Macro Score: 0.94052\n",
      " - 12s - loss: 0.0772 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 105/180\n",
      "F1 Macro Score: 0.94060\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9704\n",
      "Epoch 106/180\n",
      "F1 Macro Score: 0.94061\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 107/180\n",
      "F1 Macro Score: 0.94051\n",
      " - 12s - loss: 0.0779 - acc: 0.9710 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 108/180\n",
      "F1 Macro Score: 0.94054\n",
      " - 12s - loss: 0.0780 - acc: 0.9710 - val_loss: 0.0787 - val_acc: 0.9703\n",
      "Epoch 109/180\n",
      "F1 Macro Score: 0.94045\n",
      " - 12s - loss: 0.0773 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 110/180\n",
      "F1 Macro Score: 0.94036\n",
      " - 12s - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 111/180\n",
      "F1 Macro Score: 0.94052\n",
      " - 12s - loss: 0.0772 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 112/180\n",
      "F1 Macro Score: 0.94053\n",
      " - 12s - loss: 0.0775 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 113/180\n",
      "F1 Macro Score: 0.94051\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 114/180\n",
      "F1 Macro Score: 0.94043\n",
      " - 12s - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 115/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0771 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 116/180\n",
      "F1 Macro Score: 0.94055\n",
      " - 12s - loss: 0.0773 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 117/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0770 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 118/180\n",
      "F1 Macro Score: 0.94044\n",
      " - 12s - loss: 0.0772 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 119/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0773 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 120/180\n",
      "F1 Macro Score: 0.94057\n",
      " - 12s - loss: 0.0772 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 121/180\n",
      "F1 Macro Score: 0.94029\n",
      " - 12s - loss: 0.0779 - acc: 0.9710 - val_loss: 0.0788 - val_acc: 0.9702\n",
      "Epoch 122/180\n",
      "F1 Macro Score: 0.94030\n",
      " - 12s - loss: 0.0772 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9702\n",
      "Epoch 123/180\n",
      "F1 Macro Score: 0.94044\n",
      " - 12s - loss: 0.0770 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 124/180\n",
      "F1 Macro Score: 0.94046\n",
      " - 12s - loss: 0.0772 - acc: 0.9711 - val_loss: 0.0787 - val_acc: 0.9703\n",
      "Epoch 125/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0771 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 126/180\n",
      "F1 Macro Score: 0.94057\n",
      " - 12s - loss: 0.0770 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 127/180\n",
      "F1 Macro Score: 0.94053\n",
      " - 12s - loss: 0.0773 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 128/180\n",
      "F1 Macro Score: 0.94028\n",
      " - 12s - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0787 - val_acc: 0.9702\n",
      "Epoch 129/180\n",
      "F1 Macro Score: 0.94046\n",
      " - 12s - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 130/180\n",
      "F1 Macro Score: 0.94044\n",
      " - 12s - loss: 0.0772 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 131/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 132/180\n",
      "F1 Macro Score: 0.94036\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 133/180\n",
      "F1 Macro Score: 0.94051\n",
      " - 12s - loss: 0.0770 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 134/180\n",
      "F1 Macro Score: 0.94028\n",
      " - 12s - loss: 0.0770 - acc: 0.9712 - val_loss: 0.0787 - val_acc: 0.9703\n",
      "Epoch 135/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 136/180\n",
      "F1 Macro Score: 0.94033\n",
      " - 12s - loss: 0.0776 - acc: 0.9711 - val_loss: 0.0787 - val_acc: 0.9703\n",
      "Epoch 137/180\n",
      "F1 Macro Score: 0.94055\n",
      " - 12s - loss: 0.0769 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9704\n",
      "Epoch 138/180\n",
      "F1 Macro Score: 0.94060\n",
      " - 12s - loss: 0.0770 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9704\n",
      "Epoch 139/180\n",
      "F1 Macro Score: 0.94030\n",
      " - 12s - loss: 0.0769 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 140/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0771 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 141/180\n",
      "F1 Macro Score: 0.94045\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 142/180\n",
      "F1 Macro Score: 0.94047\n",
      " - 12s - loss: 0.0771 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 143/180\n",
      "F1 Macro Score: 0.94047\n",
      " - 12s - loss: 0.0769 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 144/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0773 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 145/180\n",
      "F1 Macro Score: 0.94045\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 146/180\n",
      "F1 Macro Score: 0.94037\n",
      " - 12s - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 147/180\n",
      "F1 Macro Score: 0.94038\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 148/180\n",
      "F1 Macro Score: 0.94025\n",
      " - 12s - loss: 0.0774 - acc: 0.9710 - val_loss: 0.0785 - val_acc: 0.9702\n",
      "Epoch 149/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 150/180\n",
      "F1 Macro Score: 0.94036\n",
      " - 12s - loss: 0.0766 - acc: 0.9713 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 151/180\n",
      "F1 Macro Score: 0.94061\n",
      " - 12s - loss: 0.0769 - acc: 0.9711 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 152/180\n",
      "F1 Macro Score: 0.94049\n",
      " - 12s - loss: 0.0768 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 153/180\n",
      "F1 Macro Score: 0.94047\n",
      " - 12s - loss: 0.0766 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 154/180\n",
      "F1 Macro Score: 0.94044\n",
      " - 12s - loss: 0.0768 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 155/180\n",
      "F1 Macro Score: 0.94040\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 156/180\n",
      "F1 Macro Score: 0.94056\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 157/180\n",
      "F1 Macro Score: 0.94031\n",
      " - 12s - loss: 0.0769 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 158/180\n",
      "F1 Macro Score: 0.94049\n",
      " - 12s - loss: 0.0774 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 159/180\n",
      "F1 Macro Score: 0.94053\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 160/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 161/180\n",
      "F1 Macro Score: 0.94033\n",
      " - 12s - loss: 0.0769 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9702\n",
      "Epoch 162/180\n",
      "F1 Macro Score: 0.94047\n",
      " - 12s - loss: 0.0765 - acc: 0.9713 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 163/180\n",
      "F1 Macro Score: 0.94051\n",
      " - 12s - loss: 0.0766 - acc: 0.9713 - val_loss: 0.0785 - val_acc: 0.9704\n",
      "Epoch 164/180\n",
      "F1 Macro Score: 0.94032\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 165/180\n",
      "F1 Macro Score: 0.94052\n",
      " - 12s - loss: 0.0766 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 166/180\n",
      "F1 Macro Score: 0.94034\n",
      " - 12s - loss: 0.0765 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9702\n",
      "Epoch 167/180\n",
      "F1 Macro Score: 0.94043\n",
      " - 12s - loss: 0.0768 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 168/180\n",
      "F1 Macro Score: 0.94043\n",
      " - 12s - loss: 0.0765 - acc: 0.9713 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 169/180\n",
      "F1 Macro Score: 0.94045\n",
      " - 12s - loss: 0.0763 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 170/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0766 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 171/180\n",
      "F1 Macro Score: 0.94034\n",
      " - 12s - loss: 0.0766 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 172/180\n",
      "F1 Macro Score: 0.94034\n",
      " - 12s - loss: 0.0767 - acc: 0.9713 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 173/180\n",
      "F1 Macro Score: 0.94046\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 174/180\n",
      "F1 Macro Score: 0.94026\n",
      " - 12s - loss: 0.0765 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 175/180\n",
      "F1 Macro Score: 0.94038\n",
      " - 12s - loss: 0.0765 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9702\n",
      "Epoch 176/180\n",
      "F1 Macro Score: 0.94029\n",
      " - 12s - loss: 0.0766 - acc: 0.9713 - val_loss: 0.0787 - val_acc: 0.9703\n",
      "Epoch 177/180\n",
      "F1 Macro Score: 0.94048\n",
      " - 12s - loss: 0.0767 - acc: 0.9712 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 178/180\n",
      "F1 Macro Score: 0.94049\n",
      " - 12s - loss: 0.0763 - acc: 0.9713 - val_loss: 0.0785 - val_acc: 0.9703\n",
      "Epoch 179/180\n",
      "F1 Macro Score: 0.94050\n",
      " - 12s - loss: 0.0766 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Epoch 180/180\n",
      "F1 Macro Score: 0.94051\n",
      " - 12s - loss: 0.0764 - acc: 0.9713 - val_loss: 0.0786 - val_acc: 0.9703\n",
      "Training fold 4 completed. macro f1 score : 0.94051\n",
      "Our training dataset shape is (1000, 4000, 23)\n",
      "Our validation dataset shape is (250, 4000, 23)\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/180\n",
      "F1 Macro Score: 0.72090\n",
      " - 23s - loss: 0.6027 - acc: 0.8275 - val_loss: 0.9383 - val_acc: 0.8746\n",
      "Epoch 2/180\n",
      "F1 Macro Score: 0.91078\n",
      " - 12s - loss: 0.1804 - acc: 0.9597 - val_loss: 0.4379 - val_acc: 0.9562\n",
      "Epoch 3/180\n",
      "F1 Macro Score: 0.92332\n",
      " - 12s - loss: 0.1419 - acc: 0.9661 - val_loss: 0.2516 - val_acc: 0.9649\n",
      "Epoch 4/180\n",
      "F1 Macro Score: 0.90618\n",
      " - 12s - loss: 0.1261 - acc: 0.9681 - val_loss: 0.1453 - val_acc: 0.9635\n",
      "Epoch 5/180\n",
      "F1 Macro Score: 0.93775\n",
      " - 12s - loss: 0.1170 - acc: 0.9689 - val_loss: 0.1096 - val_acc: 0.9691\n",
      "Epoch 6/180\n",
      "F1 Macro Score: 0.93884\n",
      " - 12s - loss: 0.1122 - acc: 0.9692 - val_loss: 0.1002 - val_acc: 0.9695\n",
      "Epoch 7/180\n",
      "F1 Macro Score: 0.93912\n",
      " - 12s - loss: 0.1101 - acc: 0.9693 - val_loss: 0.0961 - val_acc: 0.9696\n",
      "Epoch 8/180\n",
      "F1 Macro Score: 0.93841\n",
      " - 13s - loss: 0.1082 - acc: 0.9693 - val_loss: 0.1006 - val_acc: 0.9691\n",
      "Epoch 9/180\n",
      "F1 Macro Score: 0.87226\n",
      " - 12s - loss: 0.2198 - acc: 0.9399 - val_loss: 0.1843 - val_acc: 0.9452\n",
      "Epoch 10/180\n",
      "F1 Macro Score: 0.93408\n",
      " - 13s - loss: 0.1220 - acc: 0.9675 - val_loss: 0.1156 - val_acc: 0.9673\n",
      "Epoch 11/180\n",
      "F1 Macro Score: 0.93655\n",
      " - 12s - loss: 0.1123 - acc: 0.9690 - val_loss: 0.1069 - val_acc: 0.9681\n",
      "Epoch 12/180\n",
      "F1 Macro Score: 0.93893\n",
      " - 13s - loss: 0.1089 - acc: 0.9694 - val_loss: 0.0963 - val_acc: 0.9694\n",
      "Epoch 13/180\n",
      "F1 Macro Score: 0.93944\n",
      " - 12s - loss: 0.1045 - acc: 0.9697 - val_loss: 0.0941 - val_acc: 0.9697\n",
      "Epoch 14/180\n",
      "F1 Macro Score: 0.93873\n",
      " - 12s - loss: 0.1038 - acc: 0.9696 - val_loss: 0.0965 - val_acc: 0.9692\n",
      "Epoch 15/180\n",
      "F1 Macro Score: 0.93920\n",
      " - 12s - loss: 0.1026 - acc: 0.9698 - val_loss: 0.0922 - val_acc: 0.9696\n",
      "Epoch 16/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.1131 - acc: 0.9681 - val_loss: 0.0958 - val_acc: 0.9696\n",
      "Epoch 17/180\n",
      "F1 Macro Score: 0.93861\n",
      " - 13s - loss: 0.1019 - acc: 0.9698 - val_loss: 0.0966 - val_acc: 0.9694\n",
      "Epoch 18/180\n",
      "F1 Macro Score: 0.93834\n",
      " - 13s - loss: 0.1036 - acc: 0.9694 - val_loss: 0.0949 - val_acc: 0.9691\n",
      "Epoch 19/180\n",
      "F1 Macro Score: 0.93913\n",
      " - 12s - loss: 0.0997 - acc: 0.9697 - val_loss: 0.0921 - val_acc: 0.9695\n",
      "Epoch 20/180\n",
      "F1 Macro Score: 0.93947\n",
      " - 13s - loss: 0.0979 - acc: 0.9699 - val_loss: 0.0914 - val_acc: 0.9696\n",
      "Epoch 21/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0962 - acc: 0.9700 - val_loss: 0.0884 - val_acc: 0.9698\n",
      "Epoch 22/180\n",
      "F1 Macro Score: 0.93956\n",
      " - 13s - loss: 0.0945 - acc: 0.9700 - val_loss: 0.0882 - val_acc: 0.9698\n",
      "Epoch 23/180\n",
      "F1 Macro Score: 0.93855\n",
      " - 12s - loss: 0.0948 - acc: 0.9699 - val_loss: 0.0899 - val_acc: 0.9693\n",
      "Epoch 24/180\n",
      "F1 Macro Score: 0.93944\n",
      " - 12s - loss: 0.0948 - acc: 0.9699 - val_loss: 0.0880 - val_acc: 0.9697\n",
      "Epoch 25/180\n",
      "F1 Macro Score: 0.93700\n",
      " - 12s - loss: 0.0957 - acc: 0.9698 - val_loss: 0.0954 - val_acc: 0.9684\n",
      "Epoch 26/180\n",
      "F1 Macro Score: 0.93992\n",
      " - 12s - loss: 0.0930 - acc: 0.9700 - val_loss: 0.0865 - val_acc: 0.9698\n",
      "Epoch 27/180\n",
      "F1 Macro Score: 0.93841\n",
      " - 12s - loss: 0.0918 - acc: 0.9700 - val_loss: 0.0888 - val_acc: 0.9693\n",
      "Epoch 28/180\n",
      "F1 Macro Score: 0.93629\n",
      " - 12s - loss: 0.0930 - acc: 0.9699 - val_loss: 0.0929 - val_acc: 0.9685\n",
      "Epoch 29/180\n",
      "F1 Macro Score: 0.93929\n",
      " - 12s - loss: 0.0926 - acc: 0.9697 - val_loss: 0.0867 - val_acc: 0.9696\n",
      "Epoch 30/180\n",
      "F1 Macro Score: 0.93942\n",
      " - 12s - loss: 0.0914 - acc: 0.9699 - val_loss: 0.0863 - val_acc: 0.9697\n",
      "Epoch 31/180\n",
      "F1 Macro Score: 0.93962\n",
      " - 12s - loss: 0.0896 - acc: 0.9701 - val_loss: 0.0852 - val_acc: 0.9697\n",
      "Epoch 32/180\n",
      "F1 Macro Score: 0.93949\n",
      " - 12s - loss: 0.0889 - acc: 0.9701 - val_loss: 0.0856 - val_acc: 0.9697\n",
      "Epoch 33/180\n",
      "F1 Macro Score: 0.93923\n",
      " - 12s - loss: 0.0890 - acc: 0.9701 - val_loss: 0.0850 - val_acc: 0.9697\n",
      "Epoch 34/180\n",
      "F1 Macro Score: 0.93956\n",
      " - 12s - loss: 0.0888 - acc: 0.9701 - val_loss: 0.0850 - val_acc: 0.9697\n",
      "Epoch 35/180\n",
      "F1 Macro Score: 0.93914\n",
      " - 12s - loss: 0.0885 - acc: 0.9701 - val_loss: 0.0852 - val_acc: 0.9695\n",
      "Epoch 36/180\n",
      "F1 Macro Score: 0.93909\n",
      " - 13s - loss: 0.0888 - acc: 0.9699 - val_loss: 0.0858 - val_acc: 0.9695\n",
      "Epoch 37/180\n",
      "F1 Macro Score: 0.93940\n",
      " - 12s - loss: 0.0879 - acc: 0.9701 - val_loss: 0.0842 - val_acc: 0.9697\n",
      "Epoch 38/180\n",
      "F1 Macro Score: 0.93904\n",
      " - 13s - loss: 0.0879 - acc: 0.9701 - val_loss: 0.0847 - val_acc: 0.9695\n",
      "Epoch 39/180\n",
      "F1 Macro Score: 0.93940\n",
      " - 12s - loss: 0.0877 - acc: 0.9701 - val_loss: 0.0844 - val_acc: 0.9697\n",
      "Epoch 40/180\n",
      "F1 Macro Score: 0.93851\n",
      " - 13s - loss: 0.0876 - acc: 0.9701 - val_loss: 0.0855 - val_acc: 0.9693\n",
      "Epoch 41/180\n",
      "F1 Macro Score: 0.93933\n",
      " - 13s - loss: 0.0879 - acc: 0.9700 - val_loss: 0.0839 - val_acc: 0.9697\n",
      "Epoch 42/180\n",
      "F1 Macro Score: 0.93971\n",
      " - 12s - loss: 0.0869 - acc: 0.9702 - val_loss: 0.0833 - val_acc: 0.9698\n",
      "Epoch 43/180\n",
      "F1 Macro Score: 0.93982\n",
      " - 12s - loss: 0.0879 - acc: 0.9700 - val_loss: 0.0832 - val_acc: 0.9698\n",
      "Epoch 44/180\n",
      "F1 Macro Score: 0.93907\n",
      " - 13s - loss: 0.0875 - acc: 0.9700 - val_loss: 0.0844 - val_acc: 0.9695\n",
      "Epoch 45/180\n",
      "F1 Macro Score: 0.93907\n",
      " - 13s - loss: 0.0871 - acc: 0.9700 - val_loss: 0.0840 - val_acc: 0.9695\n",
      "Epoch 46/180\n",
      "F1 Macro Score: 0.93877\n",
      " - 12s - loss: 0.0869 - acc: 0.9701 - val_loss: 0.0840 - val_acc: 0.9696\n",
      "Epoch 47/180\n",
      "F1 Macro Score: 0.93955\n",
      " - 12s - loss: 0.0874 - acc: 0.9700 - val_loss: 0.0839 - val_acc: 0.9696\n",
      "Epoch 48/180\n",
      "F1 Macro Score: 0.93950\n",
      " - 12s - loss: 0.0868 - acc: 0.9701 - val_loss: 0.0830 - val_acc: 0.9697\n",
      "Epoch 49/180\n",
      "F1 Macro Score: 0.93960\n",
      " - 12s - loss: 0.0865 - acc: 0.9701 - val_loss: 0.0829 - val_acc: 0.9698\n",
      "Epoch 50/180\n",
      "F1 Macro Score: 0.93902\n",
      " - 12s - loss: 0.0866 - acc: 0.9701 - val_loss: 0.0838 - val_acc: 0.9695\n",
      "Epoch 51/180\n",
      "F1 Macro Score: 0.93942\n",
      " - 12s - loss: 0.0865 - acc: 0.9701 - val_loss: 0.0828 - val_acc: 0.9698\n",
      "Epoch 52/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 13s - loss: 0.0861 - acc: 0.9701 - val_loss: 0.0829 - val_acc: 0.9697\n",
      "Epoch 53/180\n",
      "F1 Macro Score: 0.93933\n",
      " - 12s - loss: 0.0861 - acc: 0.9701 - val_loss: 0.0830 - val_acc: 0.9697\n",
      "Epoch 54/180\n",
      "F1 Macro Score: 0.93897\n",
      " - 13s - loss: 0.0858 - acc: 0.9701 - val_loss: 0.0830 - val_acc: 0.9696\n",
      "Epoch 55/180\n",
      "F1 Macro Score: 0.93942\n",
      " - 12s - loss: 0.0857 - acc: 0.9702 - val_loss: 0.0825 - val_acc: 0.9697\n",
      "Epoch 56/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 13s - loss: 0.0854 - acc: 0.9701 - val_loss: 0.0827 - val_acc: 0.9697\n",
      "Epoch 57/180\n",
      "F1 Macro Score: 0.93937\n",
      " - 12s - loss: 0.0858 - acc: 0.9701 - val_loss: 0.0834 - val_acc: 0.9695\n",
      "Epoch 58/180\n",
      "F1 Macro Score: 0.93973\n",
      " - 12s - loss: 0.0853 - acc: 0.9702 - val_loss: 0.0824 - val_acc: 0.9698\n",
      "Epoch 59/180\n",
      "F1 Macro Score: 0.93803\n",
      " - 12s - loss: 0.0854 - acc: 0.9701 - val_loss: 0.0850 - val_acc: 0.9690\n",
      "Epoch 60/180\n",
      "F1 Macro Score: 0.93948\n",
      " - 13s - loss: 0.0853 - acc: 0.9700 - val_loss: 0.0825 - val_acc: 0.9697\n",
      "Epoch 61/180\n",
      "F1 Macro Score: 0.93927\n",
      " - 12s - loss: 0.0855 - acc: 0.9701 - val_loss: 0.0826 - val_acc: 0.9697\n",
      "Epoch 62/180\n",
      "F1 Macro Score: 0.93934\n",
      " - 12s - loss: 0.0849 - acc: 0.9702 - val_loss: 0.0823 - val_acc: 0.9697\n",
      "Epoch 63/180\n",
      "F1 Macro Score: 0.93972\n",
      " - 12s - loss: 0.0855 - acc: 0.9700 - val_loss: 0.0823 - val_acc: 0.9697\n",
      "Epoch 64/180\n",
      "F1 Macro Score: 0.93836\n",
      " - 12s - loss: 0.0877 - acc: 0.9694 - val_loss: 0.0845 - val_acc: 0.9693\n",
      "Epoch 65/180\n",
      "F1 Macro Score: 0.93842\n",
      " - 12s - loss: 0.0946 - acc: 0.9684 - val_loss: 0.0871 - val_acc: 0.9691\n",
      "Epoch 66/180\n",
      "F1 Macro Score: 0.93857\n",
      " - 12s - loss: 0.0871 - acc: 0.9700 - val_loss: 0.0843 - val_acc: 0.9694\n",
      "Epoch 67/180\n",
      "F1 Macro Score: 0.93936\n",
      " - 12s - loss: 0.0859 - acc: 0.9700 - val_loss: 0.0827 - val_acc: 0.9698\n",
      "Epoch 68/180\n",
      "F1 Macro Score: 0.93882\n",
      " - 12s - loss: 0.0857 - acc: 0.9701 - val_loss: 0.0835 - val_acc: 0.9694\n",
      "Epoch 69/180\n",
      "F1 Macro Score: 0.93928\n",
      " - 12s - loss: 0.0855 - acc: 0.9701 - val_loss: 0.0826 - val_acc: 0.9697\n",
      "Epoch 70/180\n",
      "F1 Macro Score: 0.93995\n",
      " - 12s - loss: 0.0852 - acc: 0.9702 - val_loss: 0.0821 - val_acc: 0.9698\n",
      "Epoch 71/180\n",
      "F1 Macro Score: 0.93946\n",
      " - 13s - loss: 0.0847 - acc: 0.9702 - val_loss: 0.0822 - val_acc: 0.9698\n",
      "Epoch 72/180\n",
      "F1 Macro Score: 0.93964\n",
      " - 12s - loss: 0.0859 - acc: 0.9700 - val_loss: 0.0820 - val_acc: 0.9697\n",
      "Epoch 73/180\n",
      "F1 Macro Score: 0.93960\n",
      " - 12s - loss: 0.0847 - acc: 0.9701 - val_loss: 0.0820 - val_acc: 0.9697\n",
      "Epoch 74/180\n",
      "F1 Macro Score: 0.93964\n",
      " - 13s - loss: 0.0852 - acc: 0.9701 - val_loss: 0.0820 - val_acc: 0.9697\n",
      "Epoch 75/180\n",
      "F1 Macro Score: 0.93916\n",
      " - 12s - loss: 0.0850 - acc: 0.9701 - val_loss: 0.0824 - val_acc: 0.9696\n",
      "Epoch 76/180\n",
      "F1 Macro Score: 0.93897\n",
      " - 13s - loss: 0.0847 - acc: 0.9701 - val_loss: 0.0824 - val_acc: 0.9696\n",
      "Epoch 77/180\n",
      "F1 Macro Score: 0.93931\n",
      " - 12s - loss: 0.0843 - acc: 0.9702 - val_loss: 0.0817 - val_acc: 0.9697\n",
      "Epoch 78/180\n",
      "F1 Macro Score: 0.93932\n",
      " - 13s - loss: 0.0848 - acc: 0.9701 - val_loss: 0.0822 - val_acc: 0.9696\n",
      "Epoch 79/180\n",
      "F1 Macro Score: 0.93970\n",
      " - 12s - loss: 0.0847 - acc: 0.9701 - val_loss: 0.0818 - val_acc: 0.9698\n",
      "Epoch 80/180\n",
      "F1 Macro Score: 0.93922\n",
      " - 12s - loss: 0.0848 - acc: 0.9701 - val_loss: 0.0820 - val_acc: 0.9696\n",
      "Epoch 81/180\n",
      "F1 Macro Score: 0.93945\n",
      " - 12s - loss: 0.0842 - acc: 0.9702 - val_loss: 0.0820 - val_acc: 0.9697\n",
      "Epoch 82/180\n",
      "F1 Macro Score: 0.93927\n",
      " - 13s - loss: 0.0837 - acc: 0.9703 - val_loss: 0.0822 - val_acc: 0.9695\n",
      "Epoch 83/180\n",
      "F1 Macro Score: 0.93968\n",
      " - 12s - loss: 0.0840 - acc: 0.9702 - val_loss: 0.0815 - val_acc: 0.9698\n",
      "Epoch 84/180\n",
      "F1 Macro Score: 0.93956\n",
      " - 12s - loss: 0.0840 - acc: 0.9701 - val_loss: 0.0817 - val_acc: 0.9697\n",
      "Epoch 85/180\n",
      "F1 Macro Score: 0.93920\n",
      " - 12s - loss: 0.0848 - acc: 0.9702 - val_loss: 0.0820 - val_acc: 0.9697\n",
      "Epoch 86/180\n",
      "F1 Macro Score: 0.93891\n",
      " - 13s - loss: 0.0839 - acc: 0.9702 - val_loss: 0.0820 - val_acc: 0.9696\n",
      "Epoch 87/180\n",
      "F1 Macro Score: 0.93909\n",
      " - 13s - loss: 0.0833 - acc: 0.9702 - val_loss: 0.0820 - val_acc: 0.9695\n",
      "Epoch 88/180\n",
      "F1 Macro Score: 0.93982\n",
      " - 13s - loss: 0.0834 - acc: 0.9702 - val_loss: 0.0814 - val_acc: 0.9698\n",
      "Epoch 89/180\n",
      "F1 Macro Score: 0.93948\n",
      " - 12s - loss: 0.0832 - acc: 0.9702 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 90/180\n",
      "F1 Macro Score: 0.93937\n",
      " - 12s - loss: 0.0838 - acc: 0.9702 - val_loss: 0.0817 - val_acc: 0.9696\n",
      "Epoch 91/180\n",
      "F1 Macro Score: 0.93969\n",
      " - 12s - loss: 0.0832 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 92/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 12s - loss: 0.0834 - acc: 0.9702 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 93/180\n",
      "F1 Macro Score: 0.93951\n",
      " - 12s - loss: 0.0834 - acc: 0.9702 - val_loss: 0.0814 - val_acc: 0.9697\n",
      "Epoch 94/180\n",
      "F1 Macro Score: 0.93961\n",
      " - 12s - loss: 0.0834 - acc: 0.9702 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 95/180\n",
      "F1 Macro Score: 0.93967\n",
      " - 12s - loss: 0.0832 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "Epoch 96/180\n",
      "F1 Macro Score: 0.93973\n",
      " - 12s - loss: 0.0830 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "Epoch 97/180\n",
      "F1 Macro Score: 0.93955\n",
      " - 12s - loss: 0.0849 - acc: 0.9700 - val_loss: 0.0813 - val_acc: 0.9697\n",
      "Epoch 98/180\n",
      "F1 Macro Score: 0.93960\n",
      " - 12s - loss: 0.0834 - acc: 0.9702 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 99/180\n",
      "F1 Macro Score: 0.93972\n",
      " - 13s - loss: 0.0831 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "Epoch 100/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 13s - loss: 0.0829 - acc: 0.9704 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "Epoch 101/180\n",
      "F1 Macro Score: 0.93965\n",
      " - 12s - loss: 0.0832 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "Epoch 102/180\n",
      "F1 Macro Score: 0.93968\n",
      " - 13s - loss: 0.0828 - acc: 0.9704 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 103/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 12s - loss: 0.0839 - acc: 0.9701 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 104/180\n",
      "F1 Macro Score: 0.93966\n",
      " - 12s - loss: 0.0835 - acc: 0.9702 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 105/180\n",
      "F1 Macro Score: 0.93961\n",
      " - 12s - loss: 0.0830 - acc: 0.9702 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 106/180\n",
      "F1 Macro Score: 0.93946\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 107/180\n",
      "F1 Macro Score: 0.93962\n",
      " - 12s - loss: 0.0830 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 108/180\n",
      "F1 Macro Score: 0.93976\n",
      " - 13s - loss: 0.0830 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 109/180\n",
      "F1 Macro Score: 0.93962\n",
      " - 12s - loss: 0.0828 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 110/180\n",
      "F1 Macro Score: 0.93953\n",
      " - 13s - loss: 0.0833 - acc: 0.9702 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 111/180\n",
      "F1 Macro Score: 0.93954\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0813 - val_acc: 0.9697\n",
      "Epoch 112/180\n",
      "F1 Macro Score: 0.93973\n",
      " - 13s - loss: 0.0830 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9698\n",
      "Epoch 113/180\n",
      "F1 Macro Score: 0.93973\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 114/180\n",
      "F1 Macro Score: 0.93945\n",
      " - 12s - loss: 0.0830 - acc: 0.9703 - val_loss: 0.0814 - val_acc: 0.9697\n",
      "Epoch 115/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 12s - loss: 0.0829 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 116/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0831 - acc: 0.9702 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 117/180\n",
      "F1 Macro Score: 0.93964\n",
      " - 12s - loss: 0.0835 - acc: 0.9703 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 118/180\n",
      "F1 Macro Score: 0.93953\n",
      " - 12s - loss: 0.0827 - acc: 0.9704 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 119/180\n",
      "F1 Macro Score: 0.93944\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 120/180\n",
      "F1 Macro Score: 0.93965\n",
      " - 13s - loss: 0.0832 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 121/180\n",
      "F1 Macro Score: 0.93963\n",
      " - 12s - loss: 0.0825 - acc: 0.9702 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 122/180\n",
      "F1 Macro Score: 0.93957\n",
      " - 13s - loss: 0.0830 - acc: 0.9702 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 123/180\n",
      "F1 Macro Score: 0.93954\n",
      " - 12s - loss: 0.0843 - acc: 0.9701 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 124/180\n",
      "F1 Macro Score: 0.93950\n",
      " - 12s - loss: 0.0835 - acc: 0.9702 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 125/180\n",
      "F1 Macro Score: 0.93951\n",
      " - 12s - loss: 0.0829 - acc: 0.9703 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 126/180\n",
      "F1 Macro Score: 0.93971\n",
      " - 13s - loss: 0.0828 - acc: 0.9702 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 127/180\n",
      "F1 Macro Score: 0.93917\n",
      " - 12s - loss: 0.0830 - acc: 0.9702 - val_loss: 0.0813 - val_acc: 0.9696\n",
      "Epoch 128/180\n",
      "F1 Macro Score: 0.93975\n",
      " - 13s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9698\n",
      "Epoch 129/180\n",
      "F1 Macro Score: 0.93942\n",
      " - 12s - loss: 0.0830 - acc: 0.9703 - val_loss: 0.0813 - val_acc: 0.9696\n",
      "Epoch 130/180\n",
      "F1 Macro Score: 0.93952\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 131/180\n",
      "F1 Macro Score: 0.93954\n",
      " - 12s - loss: 0.0827 - acc: 0.9704 - val_loss: 0.0811 - val_acc: 0.9697\n",
      "Epoch 132/180\n",
      "F1 Macro Score: 0.93973\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 133/180\n",
      "F1 Macro Score: 0.93974\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 134/180\n",
      "F1 Macro Score: 0.93975\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 135/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0831 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 136/180\n",
      "F1 Macro Score: 0.93963\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 137/180\n",
      "F1 Macro Score: 0.93966\n",
      " - 12s - loss: 0.0829 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 138/180\n",
      "F1 Macro Score: 0.93967\n",
      " - 12s - loss: 0.0825 - acc: 0.9704 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 139/180\n",
      "F1 Macro Score: 0.93955\n",
      " - 12s - loss: 0.0828 - acc: 0.9702 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 140/180\n",
      "F1 Macro Score: 0.93969\n",
      " - 13s - loss: 0.0824 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 141/180\n",
      "F1 Macro Score: 0.93966\n",
      " - 12s - loss: 0.0828 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 142/180\n",
      "F1 Macro Score: 0.93969\n",
      " - 12s - loss: 0.0827 - acc: 0.9702 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 143/180\n",
      "F1 Macro Score: 0.93946\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0812 - val_acc: 0.9697\n",
      "Epoch 144/180\n",
      "F1 Macro Score: 0.93951\n",
      " - 12s - loss: 0.0825 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 145/180\n",
      "F1 Macro Score: 0.93979\n",
      " - 12s - loss: 0.0828 - acc: 0.9702 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 146/180\n",
      "F1 Macro Score: 0.93979\n",
      " - 13s - loss: 0.0824 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9698\n",
      "Epoch 147/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 148/180\n",
      "F1 Macro Score: 0.93956\n",
      " - 12s - loss: 0.0828 - acc: 0.9702 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 149/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0823 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 150/180\n",
      "F1 Macro Score: 0.93968\n",
      " - 13s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9698\n",
      "Epoch 151/180\n",
      "F1 Macro Score: 0.93962\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 152/180\n",
      "F1 Macro Score: 0.93945\n",
      " - 13s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 153/180\n",
      "F1 Macro Score: 0.93955\n",
      " - 12s - loss: 0.0826 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 154/180\n",
      "F1 Macro Score: 0.93967\n",
      " - 13s - loss: 0.0821 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 155/180\n",
      "F1 Macro Score: 0.93970\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9698\n",
      "Epoch 156/180\n",
      "F1 Macro Score: 0.93962\n",
      " - 13s - loss: 0.0825 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9698\n",
      "Epoch 157/180\n",
      "F1 Macro Score: 0.93957\n",
      " - 12s - loss: 0.0823 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 158/180\n",
      "F1 Macro Score: 0.93947\n",
      " - 12s - loss: 0.0821 - acc: 0.9704 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 159/180\n",
      "F1 Macro Score: 0.93955\n",
      " - 12s - loss: 0.0818 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 160/180\n",
      "F1 Macro Score: 0.93969\n",
      " - 12s - loss: 0.0823 - acc: 0.9704 - val_loss: 0.0807 - val_acc: 0.9698\n",
      "Epoch 161/180\n",
      "F1 Macro Score: 0.93946\n",
      " - 12s - loss: 0.0827 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 162/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 12s - loss: 0.0827 - acc: 0.9702 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 163/180\n",
      "F1 Macro Score: 0.93948\n",
      " - 12s - loss: 0.0821 - acc: 0.9704 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 164/180\n",
      "F1 Macro Score: 0.93950\n",
      " - 13s - loss: 0.0823 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 165/180\n",
      "F1 Macro Score: 0.93965\n",
      " - 12s - loss: 0.0820 - acc: 0.9703 - val_loss: 0.0807 - val_acc: 0.9697\n",
      "Epoch 166/180\n",
      "F1 Macro Score: 0.93947\n",
      " - 12s - loss: 0.0824 - acc: 0.9703 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 167/180\n",
      "F1 Macro Score: 0.93926\n",
      " - 12s - loss: 0.0823 - acc: 0.9703 - val_loss: 0.0810 - val_acc: 0.9696\n",
      "Epoch 168/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0818 - acc: 0.9704 - val_loss: 0.0809 - val_acc: 0.9697\n",
      "Epoch 169/180\n",
      "F1 Macro Score: 0.93955\n",
      " - 12s - loss: 0.0821 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 170/180\n",
      "F1 Macro Score: 0.93948\n",
      " - 13s - loss: 0.0821 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 171/180\n",
      "F1 Macro Score: 0.93940\n",
      " - 12s - loss: 0.0835 - acc: 0.9702 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 172/180\n",
      "F1 Macro Score: 0.93934\n",
      " - 13s - loss: 0.0823 - acc: 0.9704 - val_loss: 0.0812 - val_acc: 0.9696\n",
      "Epoch 173/180\n",
      "F1 Macro Score: 0.93938\n",
      " - 12s - loss: 0.0834 - acc: 0.9701 - val_loss: 0.0810 - val_acc: 0.9697\n",
      "Epoch 174/180\n",
      "F1 Macro Score: 0.93951\n",
      " - 13s - loss: 0.0825 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 175/180\n",
      "F1 Macro Score: 0.93960\n",
      " - 13s - loss: 0.0821 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9698\n",
      "Epoch 176/180\n",
      "F1 Macro Score: 0.93948\n",
      " - 12s - loss: 0.0822 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 177/180\n",
      "F1 Macro Score: 0.93959\n",
      " - 12s - loss: 0.0823 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9698\n",
      "Epoch 178/180\n",
      "F1 Macro Score: 0.93954\n",
      " - 12s - loss: 0.0822 - acc: 0.9703 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 179/180\n",
      "F1 Macro Score: 0.93958\n",
      " - 12s - loss: 0.0821 - acc: 0.9704 - val_loss: 0.0808 - val_acc: 0.9697\n",
      "Epoch 180/180\n",
      "F1 Macro Score: 0.93960\n",
      " - 12s - loss: 0.0818 - acc: 0.9704 - val_loss: 0.0807 - val_acc: 0.9697\n",
      "Training fold 5 completed. macro f1 score : 0.93960\n",
      "Training completed. oof macro f1 score : 0.94056\n",
      "submission save path: ./../data/output/submission_nb087_cv_0.9406.csv\n",
      "probas save path: ./../data/output_ignore/probas_nb087_cv_0.9406\n",
      "Training completed...\n",
      "CPU times: user 1h 52min 28s, sys: 29min 34s, total: 2h 22min 2s\n",
      "Wall time: 3h 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this function run our entire program\n",
    "def run_everything():\n",
    "    \n",
    "    print(f'Reading Data Started...({time.ctime()})')\n",
    "    train, test, sample_submission = read_data()\n",
    "    train, test = normalize(train, test)\n",
    "    print(f'Reading and Normalizing Data Completed')\n",
    "        \n",
    "    print(f'Creating Features({time.ctime()})')\n",
    "    print(f'Feature Engineering Started...')\n",
    "    train = run_feat_engineering(train, batch_size = GROUP_BATCH_SIZE)\n",
    "    test = run_feat_engineering(test, batch_size = GROUP_BATCH_SIZE)\n",
    "    train, test, features = feature_selection(train, test)\n",
    "    print(f'Feature Engineering Completed...')\n",
    "        \n",
    "   \n",
    "    print(f'Training Wavenet model with {SPLITS} folds of GroupKFold Started...({time.ctime()})')\n",
    "    oof_ = run_cv_model_by_batch(train, test, SPLITS, 'group', features, sample_submission, EPOCHS, NNBATCHSIZE)\n",
    "    print(f'Training completed...')\n",
    "    \n",
    "    return oof_\n",
    "        \n",
    "oof_ = run_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(PATH_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = []\n",
    "for n in range(10):\n",
    "    batchs = np.ones(500000)*n\n",
    "    batch_list.append(batchs.astype(int))\n",
    "batch_list = np.hstack(batch_list)\n",
    "df_tr['batch'] = batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group 特徴量を作成\n",
    "group = group_feat_train(df_tr)\n",
    "df_tr = pd.concat([df_tr, group], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_tr['open_channels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.argmax(oof_, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_score(0): 0.999618\n",
      "group_score(1): 0.986131\n",
      "group_score(2): 0.978231\n",
      "group_score(3): 0.997748\n",
      "group_score(4): 0.890533\n"
     ]
    }
   ],
   "source": [
    "for group in sorted(df_tr['group'].unique()):\n",
    "    idxs = df_tr['group'] == group\n",
    "    oof_grp = oof[idxs].astype(int)\n",
    "    y_grp = y[idxs]\n",
    "    print(f'group_score({group}): {f1_score(y_grp, oof_grp, average=\"micro\"):4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = df_tr.loc[df_tr['batch']==3]['signal'].max() \n",
    "min_ = df_tr.loc[df_tr['batch']==3]['signal'].min() \n",
    "idxs = (df_tr['batch']==7) & (df_tr['signal']>max_)\n",
    "df_tr['signal'][idxs] = max_\n",
    "idxs = (df_tr['batch']==7) & (df_tr['signal']<min_)\n",
    "df_tr['signal'][idxs] = min_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx = np.arange(len(df_tr))\n",
    "idxs = y != oof\n",
    "\n",
    "failed = np.zeros(len(df_tr))\n",
    "failed[idxs] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "b = np.ones(n)/n\n",
    "failed_move = np.convolve(failed, b, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5500000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 6))\n",
    "axs = axs.ravel()\n",
    "# fig = plt.figure(figsize=(20, 3))\n",
    "\n",
    "for i_gr, group in enumerate(sorted(df_tr['group'].unique())):\n",
    "    idxs = df_tr['group'] == group\n",
    "    axs[0].plot(np.arange(len(df_tr))[idxs], df_tr['signal'].values[idxs], color=cp[i_gr], label=f'group={group}')\n",
    "for x in range(10): \n",
    "    axs[0].axvline(x*500000 + 500000, color='gray') \n",
    "    axs[0].text(x*500000 + 250000, 5, x)\n",
    "axs[0].plot(x_idx, failed_move*10, '.', color='black', label='failed_mv')\n",
    "axs[0].set_xlim(0, 5500000)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x_idx, y)\n",
    "axs[1].set_xlim(0, 5500000)\n",
    "\n",
    "# fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
